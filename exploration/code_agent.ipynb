{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d66d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.runtime import Runtime\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from IPython.display import display, Image\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Protocol, TypedDict, Any, List, Optional, Annotated\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from rich.markdown import Markdown\n",
    "from rich.console import Console\n",
    "import asyncio\n",
    "from variable_importance.utils.output_manager import OutputManager\n",
    "from variable_importance.utils.code_executer import OutputCapturingExecutor, ExecutionResult\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8b16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, TypeAlias\n",
    "from dataclasses import Field as DataclassField\n",
    "\n",
    "JOKE_RATING = Literal['funny', 'not-funny']\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    joke_rating: JOKE_RATING\n",
    "    joke_critique: str\n",
    "    final_joke: str\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:12b\",\n",
    "    base_url=\"http://100.91.155.118:11434\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f56ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: State):\n",
    "    # Implementation to generate and improve jokes based on the state\n",
    "    class JokeOutput(BaseModel):\n",
    "        joke: str = Field(..., description=\"The generated joke\")\n",
    "    joke_llm = llm.with_structured_output(JokeOutput)\n",
    "\n",
    "    if state.get(\"joke_critique\"):\n",
    "        joke: JokeOutput = joke_llm.invoke(f\"Improve the following joke based on this critique: {state['joke_critique']}. The original joke is: {state['joke']}\")\n",
    "    else:\n",
    "        joke: JokeOutput = joke_llm.invoke(f\"Tell me a joke about {state['topic']}\")\n",
    "\n",
    "    return {\"joke\": joke.joke}\n",
    "    \n",
    "   \n",
    "\n",
    "def critique_joke(state: State):\n",
    "    class Critique(BaseModel):\n",
    "        critique: str = Field(..., description=\"Critique of the joke and suggestions for improvement\")\n",
    "        rating: Literal['funny', 'not-funny'] = Field(..., description=\"Rating of the joke as funny or not-funny. If the joke is funny, rate it as 'funny', otherwise rate it as 'not-funny'.\")\n",
    "    critique_llm = llm.with_structured_output(Critique)\n",
    "    \n",
    "    joke = state.get(\"joke\", \"\")\n",
    "    rating = critique_llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"You are a professional comedy critic. Provide constructive feedback on the joke provided by the user, focusing on humor, originality, and relevance to the topic. Also, rate the joke as either 'funny' or 'not-funny'. If the joke is funny, rate it as 'funny', otherwise rate it as 'not-funny'.\"),\n",
    "            HumanMessage(content=f\"Here is the joke for the topic {state['topic']}: {joke}\"),\n",
    "        ]\n",
    "    )\n",
    "    return {\"joke_critique\": rating.critique, \"joke_rating\": rating.rating}\n",
    "    \n",
    "\n",
    "def check_completion(state: State):\n",
    "    \n",
    "    if state.get(\"joke_rating\", \"not-funny\") == \"funny\":\n",
    "        return \"Complete\"\n",
    "    return \"In Progress\"\n",
    "    \n",
    "def polish_joke(state: State):\n",
    "    class PolishedJoke(BaseModel):\n",
    "        final_joke: str = Field(..., description=\"The polished final version of the joke\")\n",
    "    \n",
    "    polish_llm = llm.with_structured_output(PolishedJoke)\n",
    "    if state.get(\"joke\"):\n",
    "        polished = polish_llm.invoke(\n",
    "            [\n",
    "                SystemMessage(content=\"You are a professional comedian. Polish and enhance the following joke to make it more engaging and humorous. Also, address any critiques provided. Only return the final joke without any additional commentary.\"),\n",
    "                HumanMessage(content=f\"Polish the following joke: {state['joke']} and address the critiques: {state.get('joke_critique', '')}\")\n",
    "            ]\n",
    "            )\n",
    "        return {\"final_joke\": polished.final_joke}\n",
    "    return {}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1c4dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from IPython.display import display, Image\n",
    "\n",
    "joke_graph = StateGraph(State)\n",
    "\n",
    "joke_graph.add_node(\"generate_joke\", generate_joke)\n",
    "joke_graph.add_node(\"critique_joke\", critique_joke)\n",
    "joke_graph.add_node(\"polish_joke\", polish_joke)\n",
    "\n",
    "joke_graph.add_edge(START, \"generate_joke\")\n",
    "joke_graph.add_edge(\"generate_joke\", \"critique_joke\")\n",
    "\n",
    "joke_graph.add_conditional_edges(\n",
    "    \"critique_joke\",\n",
    "    check_completion,\n",
    "    {\n",
    "        \"In Progress\": \"generate_joke\",\n",
    "        \"Complete\": \"polish_joke\",\n",
    "    },\n",
    ")\n",
    "\n",
    "joke_graph.add_edge(\"polish_joke\", END)\n",
    "\n",
    "chain = joke_graph.compile()\n",
    "display(Image(chain.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29da6db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Node generate_joke -----\n",
      "{\n",
      "  \"joke\": \"Why did the data scientist break up with the statistician?\\n\\nBecause they said their relationship lacked significance!\"\n",
      "}\n",
      "-----Finished Node-----\n",
      "----- Node critique_joke -----\n",
      "{\n",
      "  \"critique\": \"Okay, let's break down this Data Science joke. The setup ‚Äì a breakup scenario ‚Äì is a solid, relatable starting point. The punchline, 'Because they said their relationship lacked significance!' is *directly* tied to a core statistical concept. That's a big plus ‚Äì it shows you understand the topic and are trying to incorporate it into the humor. \\n\\nHowever, the joke lands a little flat. It's a very *literal* interpretation of 'statistical significance.' While clever in its directness, it lacks a layer of unexpectedness or a playful twist. It's almost *too* on-the-nose. A truly great Data Science joke often finds humor in the absurdity of the field, or the quirks of the people in it. This one feels a bit like a textbook example of a pun.\\n\\nTo improve it, consider: \\n* **Adding a layer of irony:** Maybe the statistician was *trying* to be romantic, but kept analyzing their dates with p-values. \\n* **Playing with the double meaning:** 'Significance' can mean importance, but also statistical significance. A more surprising connection could be more humorous.\\n* **Adding a character element:** What was the data scientist's personality? Were they overly analytical? Did the statistician have a dry sense of humor?\",\n",
      "  \"rating\": \"not-funny\"\n",
      "}\n",
      "-----Finished Node-----\n",
      "----- Node generate_joke -----\n",
      "{\n",
      "  \"joke\": \"Why did the data scientist break up with the statistician?\\n\\nShe said, 'Every time I tried to be romantic, you's just calculating the p-value of my gestures. Apparently, my surprise picnic only achieved a significance level of 0.06!'\"\n",
      "}\n",
      "\n",
      "   \t \t \t \t \t \t \t \t \t\n",
      "-----Finished Node-----\n",
      "----- Node critique_joke -----\n",
      "{\n",
      "  \"critique\": \"Okay, let's break down this Data Science joke. The core concept ‚Äì a data scientist and statistician relationship falling apart due to overly analytical behavior ‚Äì is genuinely promising. It taps into a recognizable stereotype within the field, which is a good starting point for humor. The 'p-value' reference is spot-on and demonstrates a solid understanding of the jargon. It's the kind of detail that will resonate with people familiar with data science. \\n\\nHowever, the execution needs a little polish. The phrasing 'you's just calculating...' feels a bit clunky and doesn't quite land with the intended comedic rhythm. It's grammatically awkward and pulls the listener out of the joke. The 'significance level of 0.06!' is a good detail, but the explanation feels a little *too* explanatory. Jokes often work best when the punchline is surprising and doesn't need to be spelled out. The audience should *get* the joke, not be told what it means.\\n\\nTo improve it, I'd suggest streamlining the delivery and focusing on the absurdity of the situation. Perhaps something like: 'I broke up with a statistician. Apparently, my surprise picnic only achieved a significance level of 0.06 ‚Äì not romantic enough!' or even just 'My statistician ex said my surprise picnic wasn't significant enough.' Less explanation, more punch.\\n\\n**Areas for Improvement:**\\n*   **Delivery:** The phrasing is a bit awkward.\\n*   **Explanation:** The explanation of the p-value detracts from the humor.\\n*   **Conciseness:** Shorter is often funnier.\",\n",
      "  \"rating\": \"not-funny\"\n",
      "}\n",
      "-----Finished Node-----\n",
      "----- Node generate_joke -----\n",
      "{\"joke\": \"Why did the data scientist break up with the statistician?\\n\\nShe said, 'My romantic gestures just weren't statistically significant.'\"}\n",
      "\n",
      "-----Finished Node-----\n",
      "----- Node critique_joke -----\n",
      "{\n",
      "  \"critique\": \"Okay, let's break down this joke. The premise ‚Äì a data scientist and statistician relationship ‚Äì is inherently amusing because it plays on the often-perceived rivalry and nuanced differences between the two fields. It's a solid starting point. The punchline, 'She said, 'My romantic gestures just weren't statistically significant,' is where it gets interesting. It's clever in its direct application of data science terminology to a relationship context. The humor comes from the absurdity of applying such a technical concept to something as personal as romance. \\n\\n**Strengths:**\\n*   **Conceptually Strong:** The core idea of a data scientist/statistician relationship is funny.\\n*   **Good Use of Jargon:** The phrase 'statistically significant' is used correctly and in a way that's recognizable to those familiar with the field.\\n*   **Unexpected Twist:** It's not the typical breakup reason, which adds to the humor.\\n\\n**Areas for Improvement:**\\n*   **Predictability:** While the joke is clever, the connection between data science and a breakup is becoming a fairly common trope. It's not *bad*, but it lacks a bit of freshness.\\n*   **Delivery:** The joke relies heavily on the audience understanding the term 'statistically significant.' If the audience isn't familiar, the joke falls flat. A brief, subtle explanation (perhaps through the delivery) could help.\\n*   **Potential for More Absurdity:** You could push the absurdity further. Maybe the data scientist was trying to quantify the romance with A/B testing or sentiment analysis. That would amplify the humor.\",\n",
      "  \"rating\": \"funny\"\n",
      "}\n",
      "-----Finished Node-----\n",
      "----- Node polish_joke -----\n",
      "{\n",
      "    \"final_joke\": \"Why did the data scientist break up with the statistician? She said, 'Our dates were just‚Ä¶ inconclusive. I ran an A/B test ‚Äì candlelight dinner versus pizza ‚Äì and the results were not statistically significant. Plus, he kept trying to build a confidence interval around my feelings.'\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "first_node = None\n",
    "content = \"\"\n",
    "for token, metadata in chain.stream({\"topic\": \"Data Science\"}, stream_mode='messages'):\n",
    "    if first_node is None:\n",
    "        first_node = metadata['langgraph_node']\n",
    "        print(f\"----- Node {first_node} -----\")\n",
    "    this_node = metadata['langgraph_node']\n",
    "    if this_node != first_node:\n",
    "        first_node = this_node\n",
    "        print('\\n-----Finished Node-----')\n",
    "        print(f\"----- Node {first_node} -----\")\n",
    "        content = \"\"\n",
    "    content += token.content\n",
    "    if token.content:\n",
    "        print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e405f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_data_to_folder(input_path: str, output_path: str) -> None:\n",
    "    import shutil\n",
    "    if not os.path.exists(os.path.dirname(output_path)):\n",
    "        os.makedirs(os.path.dirname(output_path))\n",
    "    shutil.copy(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea5809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9b69e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    from chromadb.config import Settings\n",
    "    CHROMADB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CHROMADB_AVAILABLE = False\n",
    "    logger.warning(\"‚ö†Ô∏è ChromaDB not available. Install with: pip install chromadb\")\n",
    "\n",
    "\n",
    "class TextChunker:\n",
    "    \"\"\"\n",
    "    Intelligent text chunking for RAG system.\n",
    "    \n",
    "    Splits text into smaller, focused segments while preserving context.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 500, overlap: int = 50):\n",
    "        \"\"\"\n",
    "        Initialize text chunker.\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: Target size for each chunk (in characters)\n",
    "            overlap: Number of characters to overlap between chunks\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.overlap = overlap\n",
    "        logger.info(f\"üìù TextChunker initialized (chunk_size={chunk_size}, overlap={overlap})\")\n",
    "    \n",
    "    def chunk_text(self, text: str, metadata: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Chunk text into smaller, focused segments.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to chunk\n",
    "            metadata: Base metadata to attach to all chunks\n",
    "            \n",
    "        Returns:\n",
    "            List of chunk dictionaries with text and metadata\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        # Small text - no chunking needed\n",
    "        if len(text) <= self.chunk_size:\n",
    "            return [{\n",
    "                \"text\": text,\n",
    "                \"metadata\": {\n",
    "                    **(metadata or {}),\n",
    "                    \"chunk_index\": 0,\n",
    "                    \"total_chunks\": 1,\n",
    "                    \"chunk_size\": len(text)\n",
    "                }\n",
    "            }]\n",
    "        \n",
    "        # Split into sentences (preserve sentence boundaries)\n",
    "        sentences = re.split(r'(?<=[.!?\\n])\\s+', text)\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_size = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence_size = len(sentence)\n",
    "            \n",
    "            # Start new chunk if adding sentence exceeds size\n",
    "            if current_size + sentence_size > self.chunk_size and current_chunk:\n",
    "                chunk_text = \" \".join(current_chunk)\n",
    "                chunks.append(chunk_text)\n",
    "                \n",
    "                # Keep overlap from previous chunk\n",
    "                if self.overlap > 0 and len(chunk_text) > self.overlap:\n",
    "                    overlap_text = chunk_text[-self.overlap:]\n",
    "                    # Find sentence boundary in overlap\n",
    "                    last_period = overlap_text.rfind('. ')\n",
    "                    if last_period != -1:\n",
    "                        overlap_text = overlap_text[last_period + 2:]\n",
    "                    \n",
    "                    current_chunk = [overlap_text]\n",
    "                    current_size = len(overlap_text)\n",
    "                else:\n",
    "                    current_chunk = []\n",
    "                    current_size = 0\n",
    "            \n",
    "            current_chunk.append(sentence)\n",
    "            current_size += sentence_size + 1  # +1 for space\n",
    "        \n",
    "        # Add final chunk\n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "        \n",
    "        # Create chunk dictionaries with metadata\n",
    "        total_chunks = len(chunks)\n",
    "        result = []\n",
    "        \n",
    "        for idx, chunk_text in enumerate(chunks):\n",
    "            chunk_metadata = {\n",
    "                **(metadata or {}),\n",
    "                \"chunk_index\": idx,\n",
    "                \"total_chunks\": total_chunks,\n",
    "                \"chunk_size\": len(chunk_text)\n",
    "            }\n",
    "            result.append({\n",
    "                \"text\": chunk_text,\n",
    "                \"metadata\": chunk_metadata\n",
    "            })\n",
    "        \n",
    "        logger.debug(f\"üìù Chunked text into {total_chunks} segments\")\n",
    "        return result\n",
    "\n",
    "\n",
    "class ContextRAG:\n",
    "    \"\"\"\n",
    "    Enhanced RAG system with chunking for better context retrieval.\n",
    "    \n",
    "    Features:\n",
    "    - Stores chunks instead of full documents\n",
    "    - Better semantic search granularity\n",
    "    - Focused context for LLM queries\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        collection_name: str = \"workflow_context\",\n",
    "        persist_directory: str = \"cache/rag_db\",\n",
    "        chunk_size: int = 500,\n",
    "        chunk_overlap: int = 50\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the RAG system.\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the database\n",
    "            chunk_size: Size of text chunks\n",
    "            chunk_overlap: Overlap between chunks\n",
    "        \"\"\"\n",
    "        if not CHROMADB_AVAILABLE:\n",
    "            logger.error(\"‚ùå ChromaDB not available. RAG system disabled.\")\n",
    "            self.enabled = False\n",
    "            return\n",
    "        \n",
    "        self.enabled = True\n",
    "        self.persist_directory = Path(persist_directory).resolve()\n",
    "        self.persist_directory.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize chunker\n",
    "        self.chunker = TextChunker(chunk_size=chunk_size, overlap=chunk_overlap)\n",
    "        \n",
    "        # Initialize ChromaDB client\n",
    "        self.client = chromadb.PersistentClient(\n",
    "            path=str(self.persist_directory),\n",
    "            settings=Settings(\n",
    "                anonymized_telemetry=False,\n",
    "                allow_reset=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Get or create collection\n",
    "        try:\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=collection_name,\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "            logger.info(f\"üìö ContextRAG initialized: {collection_name}\")\n",
    "            logger.info(f\"   Stored documents: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to initialize collection: {e}\")\n",
    "            self.enabled = False\n",
    "    \n",
    "    def _generate_id(self, content: str, doc_type: str, chunk_idx: int = 0) -> str:\n",
    "        \"\"\"Generate a unique ID for a chunk.\"\"\"\n",
    "        hash_input = f\"{doc_type}:{content[:100]}:{chunk_idx}:{datetime.now().isoformat()}\"\n",
    "        return hashlib.md5(hash_input.encode()).hexdigest()\n",
    "    \n",
    "    def _clean_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Clean metadata for ChromaDB compatibility.\n",
    "        ChromaDB only accepts: str, int, float, bool, or None values.\n",
    "        \"\"\"\n",
    "        cleaned = {}\n",
    "        for key, value in metadata.items():\n",
    "            if value is None:\n",
    "                cleaned[key] = None\n",
    "            elif isinstance(value, (str, int, float, bool)):\n",
    "                cleaned[key] = value\n",
    "            elif isinstance(value, list):\n",
    "                if len(value) == 0:\n",
    "                    cleaned[key] = \"\"\n",
    "                elif all(isinstance(v, str) for v in value):\n",
    "                    cleaned[key] = \", \".join(value)\n",
    "                else:\n",
    "                    cleaned[key] = str(value)\n",
    "            elif isinstance(value, dict):\n",
    "                import json\n",
    "                cleaned[key] = json.dumps(value)\n",
    "            else:\n",
    "                cleaned[key] = str(value)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def add_plot_analysis(\n",
    "        self,\n",
    "        plot_name: str,\n",
    "        plot_path: str,\n",
    "        analysis: str,\n",
    "        stage_name: str,\n",
    "        workflow_id: str,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Add a plot analysis to the RAG system with chunking.\n",
    "        \n",
    "        Args:\n",
    "            plot_name: Name of the plot file\n",
    "            plot_path: Path to the plot file\n",
    "            analysis: Analysis text from vision LLM\n",
    "            stage_name: Workflow stage name\n",
    "            workflow_id: Workflow ID\n",
    "            metadata: Additional metadata\n",
    "        \"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Prepare base metadata\n",
    "            base_metadata = {\n",
    "                \"type\": \"plot_analysis\",\n",
    "                \"plot_name\": plot_name,\n",
    "                \"plot_path\": plot_path,\n",
    "                \"stage_name\": stage_name,\n",
    "                \"workflow_id\": workflow_id,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            if metadata:\n",
    "                base_metadata.update(metadata)\n",
    "            \n",
    "            # Chunk the analysis\n",
    "            doc_text = f\"Plot: {plot_name}\\n\\nAnalysis:\\n{analysis}\"\n",
    "            chunks = self.chunker.chunk_text(doc_text, base_metadata)\n",
    "            \n",
    "            # Add all chunks to collection\n",
    "            documents = []\n",
    "            metadatas = []\n",
    "            ids = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                chunk_text = chunk[\"text\"]\n",
    "                chunk_metadata = self._clean_metadata(chunk[\"metadata\"])\n",
    "                chunk_id = self._generate_id(chunk_text, \"plot_analysis\", chunk[\"metadata\"][\"chunk_index\"])\n",
    "                \n",
    "                documents.append(chunk_text)\n",
    "                metadatas.append(chunk_metadata)\n",
    "                ids.append(chunk_id)\n",
    "            \n",
    "            self.collection.add(\n",
    "                documents=documents,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"üìä Added plot analysis to RAG: {plot_name} ({len(chunks)} chunks)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to add plot analysis: {e}\")\n",
    "    \n",
    "    def add_code_execution(\n",
    "        self,\n",
    "        code: str,\n",
    "        stdout: str,\n",
    "        stderr: str,\n",
    "        stage_name: str,\n",
    "        workflow_id: str,\n",
    "        success: bool,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Add code execution results to RAG with chunking.\n",
    "        \n",
    "        Args:\n",
    "            code: Executed code\n",
    "            stdout: Standard output\n",
    "            stderr: Standard error\n",
    "            stage_name: Workflow stage name\n",
    "            workflow_id: Workflow ID\n",
    "            success: Whether execution was successful\n",
    "            metadata: Additional metadata\n",
    "        \"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Prepare base metadata\n",
    "            base_metadata = {\n",
    "                \"type\": \"code_execution\",\n",
    "                \"stage_name\": stage_name,\n",
    "                \"workflow_id\": workflow_id,\n",
    "                \"success\": success,\n",
    "                \"has_error\": bool(stderr),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"code_length\": len(code),\n",
    "                \"output_length\": len(stdout)\n",
    "            }\n",
    "            \n",
    "            if metadata:\n",
    "                base_metadata.update(metadata)\n",
    "            \n",
    "            # Create document text\n",
    "            doc_text = f\"\"\"\n",
    "Stage: {stage_name}\n",
    "Status: {'Success' if success else 'Failed'}\n",
    "\n",
    "Code:\n",
    "{code}\n",
    "\n",
    "Output:\n",
    "{stdout}\n",
    "\"\"\"\n",
    "            \n",
    "            if stderr:\n",
    "                doc_text += f\"\\nErrors:\\n{stderr}\"\n",
    "            \n",
    "            # Chunk the document\n",
    "            chunks = self.chunker.chunk_text(doc_text, base_metadata)\n",
    "            \n",
    "            # Add all chunks\n",
    "            documents = []\n",
    "            metadatas = []\n",
    "            ids = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                chunk_text = chunk[\"text\"]\n",
    "                chunk_metadata = self._clean_metadata(chunk[\"metadata\"])\n",
    "                chunk_id = self._generate_id(chunk_text, \"code_execution\", chunk[\"metadata\"][\"chunk_index\"])\n",
    "                \n",
    "                documents.append(chunk_text)\n",
    "                metadatas.append(chunk_metadata)\n",
    "                ids.append(chunk_id)\n",
    "            \n",
    "            self.collection.add(\n",
    "                documents=documents,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"üíª Added code execution to RAG: {stage_name} ({len(chunks)} chunks)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to add code execution: {e}\")\n",
    "    \n",
    "    def add_summary(\n",
    "        self,\n",
    "        summary: str,\n",
    "        stage_name: str,\n",
    "        workflow_id: str,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        \"\"\"Add a summary to RAG with chunking.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            base_metadata = {\n",
    "                \"type\": \"summary\",\n",
    "                \"stage_name\": stage_name,\n",
    "                \"workflow_id\": workflow_id,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            if metadata:\n",
    "                base_metadata.update(metadata)\n",
    "            \n",
    "            doc_text = f\"Summary for {stage_name}:\\n{summary}\"\n",
    "            chunks = self.chunker.chunk_text(doc_text, base_metadata)\n",
    "            \n",
    "            documents = []\n",
    "            metadatas = []\n",
    "            ids = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                chunk_text = chunk[\"text\"]\n",
    "                chunk_metadata = self._clean_metadata(chunk[\"metadata\"])\n",
    "                chunk_id = self._generate_id(chunk_text, \"summary\", chunk[\"metadata\"][\"chunk_index\"])\n",
    "                \n",
    "                documents.append(chunk_text)\n",
    "                metadatas.append(chunk_metadata)\n",
    "                ids.append(chunk_id)\n",
    "            \n",
    "            self.collection.add(\n",
    "                documents=documents,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"üìù Added summary to RAG: {stage_name} ({len(chunks)} chunks)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to add summary: {e}\")\n",
    "    \n",
    "    def query_relevant_context(\n",
    "        self,\n",
    "        query: str,\n",
    "        workflow_id: Optional[str] = None,\n",
    "        stage_name: Optional[str] = None,\n",
    "        doc_types: Optional[List[str]] = None,\n",
    "        n_results: int = 10\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Query for relevant context chunks.\n",
    "        \n",
    "        Args:\n",
    "            query: User query text\n",
    "            workflow_id: Filter by workflow ID\n",
    "            stage_name: Filter by stage name\n",
    "            doc_types: Filter by document types\n",
    "            n_results: Number of results to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of relevant context chunks with metadata\n",
    "        \"\"\"\n",
    "        if not self.enabled:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Build where filter\n",
    "            where_filter = None\n",
    "            \n",
    "            if workflow_id and doc_types:\n",
    "                where_filter = {\n",
    "                    \"$and\": [\n",
    "                        {\"workflow_id\": workflow_id},\n",
    "                        {\"type\": {\"$in\": doc_types}}\n",
    "                    ]\n",
    "                }\n",
    "            elif workflow_id and stage_name:\n",
    "                where_filter = {\n",
    "                    \"$and\": [\n",
    "                        {\"workflow_id\": workflow_id},\n",
    "                        {\"stage_name\": stage_name}\n",
    "                    ]\n",
    "                }\n",
    "            elif workflow_id:\n",
    "                where_filter = {\"workflow_id\": workflow_id}\n",
    "            elif stage_name:\n",
    "                where_filter = {\"stage_name\": stage_name}\n",
    "            elif doc_types:\n",
    "                where_filter = {\"type\": {\"$in\": doc_types}}\n",
    "            \n",
    "            # Query the collection\n",
    "            results = self.collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=n_results,\n",
    "                where=where_filter\n",
    "            )\n",
    "            \n",
    "            if not results['documents'] or not results['documents'][0]:\n",
    "                logger.info(f\"üîç No relevant context found for query\")\n",
    "                return []\n",
    "            \n",
    "            # Format results\n",
    "            contexts = []\n",
    "            for i, doc in enumerate(results['documents'][0]):\n",
    "                context = {\n",
    "                    \"document\": doc,\n",
    "                    \"metadata\": results['metadatas'][0][i],\n",
    "                    \"distance\": results['distances'][0][i] if 'distances' in results else None\n",
    "                }\n",
    "                contexts.append(context)\n",
    "            \n",
    "            logger.info(f\"üîç Retrieved {len(contexts)} relevant context chunks\")\n",
    "            return contexts\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to query context: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_context_summary(\n",
    "        self,\n",
    "        query: str,\n",
    "        workflow_id: Optional[str] = None,\n",
    "        stage_name: Optional[str] = None,\n",
    "        max_tokens: int = 2000\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get a concise context summary relevant to the query.\n",
    "        \n",
    "        Combines relevant chunks into a focused context string.\n",
    "        \"\"\"\n",
    "        if not self.enabled:\n",
    "            return \"\"\n",
    "        \n",
    "        contexts = self.query_relevant_context(\n",
    "            query=query,\n",
    "            workflow_id=workflow_id,\n",
    "            stage_name=stage_name,\n",
    "            n_results=15  # Get more chunks since they're smaller\n",
    "        )\n",
    "        \n",
    "        if not contexts:\n",
    "            return \"\"\n",
    "        \n",
    "        # Build context string\n",
    "        context_parts = []\n",
    "        total_length = 0\n",
    "        max_chars = max_tokens * 4  # Rough approximation\n",
    "        \n",
    "        # Group chunks by document\n",
    "        doc_groups = {}\n",
    "        for ctx in contexts:\n",
    "            doc_type = ctx['metadata'].get('type', 'unknown')\n",
    "            stage = ctx['metadata'].get('stage_name', 'unknown')\n",
    "            chunk_idx = ctx['metadata'].get('chunk_index', 0)\n",
    "            \n",
    "            key = f\"{doc_type}:{stage}\"\n",
    "            if key not in doc_groups:\n",
    "                doc_groups[key] = []\n",
    "            doc_groups[key].append((chunk_idx, ctx))\n",
    "        \n",
    "        # Add grouped chunks to context\n",
    "        for key, chunks in doc_groups.items():\n",
    "            # Sort chunks by index\n",
    "            chunks.sort(key=lambda x: x[0])\n",
    "            \n",
    "            doc_type, stage = key.split(':', 1)\n",
    "            context_parts.append(f\"\\n[{doc_type.upper()} - {stage}]\")\n",
    "            \n",
    "            for _, ctx in chunks:\n",
    "                doc_text = ctx['document']\n",
    "                logger.debug(f\"Adding chunk (type={doc_type}, stage={stage}, size={len(doc_text)}) to context\")\n",
    "                if total_length + len(doc_text) > max_chars:\n",
    "                    remaining = max_chars - total_length\n",
    "                    if remaining > 100:\n",
    "                        doc_text = doc_text[:remaining] + \"...\"\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                context_parts.append(doc_text)\n",
    "                total_length += len(doc_text)\n",
    "                \n",
    "                if total_length >= max_chars:\n",
    "                    break\n",
    "            \n",
    "            if total_length >= max_chars:\n",
    "                break\n",
    "        logger.debug(f\"Total context length: {total_length} characters\")\n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "\n",
    "    def delete_by_workflow(self, workflow_id: str):\n",
    "        \"\"\"Delete all documents for a specific workflow.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            results = self.collection.get(\n",
    "                where={\"workflow_id\": workflow_id}\n",
    "            )\n",
    "            \n",
    "            if results['ids']:\n",
    "                self.collection.delete(ids=results['ids'])\n",
    "                logger.info(f\"üóëÔ∏è Deleted {len(results['ids'])} chunks for workflow: {workflow_id}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to delete workflow documents: {e}\")\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get RAG system statistics.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return {\"enabled\": False}\n",
    "        \n",
    "        try:\n",
    "            total_count = self.collection.count()\n",
    "            \n",
    "            # Get type breakdown\n",
    "            results = self.collection.get()\n",
    "            type_counts = {}\n",
    "            if results['metadatas']:\n",
    "                for metadata in results['metadatas']:\n",
    "                    doc_type = metadata.get('type', 'unknown')\n",
    "                    type_counts[doc_type] = type_counts.get(doc_type, 0) + 1\n",
    "            \n",
    "            return {\n",
    "                \"enabled\": True,\n",
    "                \"total_chunks\": total_count,\n",
    "                \"type_breakdown\": type_counts,\n",
    "                \"persist_directory\": str(self.persist_directory),\n",
    "                \"collection_name\": self.collection.name,\n",
    "                \"chunk_size\": self.chunker.chunk_size,\n",
    "                \"chunk_overlap\": self.chunker.overlap\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to get stats: {e}\")\n",
    "            return {\"enabled\": True, \"error\": str(e)}\n",
    "    \n",
    "    def clear_all(self):\n",
    "        \"\"\"Clear all documents from the RAG system.\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            self.client.delete_collection(self.collection.name)\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=self.collection.name,\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "            logger.info(\"üóëÔ∏è Cleared all RAG chunks\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Failed to clear RAG: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99641648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-22 12:05:16.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1müìù TextChunker initialized (chunk_size=500, overlap=50)\u001b[0m\n",
      "\u001b[32m2025-11-22 12:05:16.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1müìö ContextRAG initialized: workflow_context\u001b[0m\n",
      "\u001b[32m2025-11-22 12:05:16.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1m   Stored documents: 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "context_rag = ContextRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c482a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-22 12:06:35.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_relevant_context\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1müîç No relevant context found for query\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_rag.get_context_summary(\n",
    "    query=\"What are the key factors influencing variable importance in machine learning models?\",\n",
    "    workflow_id=None,\n",
    "    stage_name=None,\n",
    "    max_tokens=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3696e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current time as a string.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# @tool\n",
    "# def search_current_knoweledge(query: str) -> str:\n",
    "#     \"\"\"Query a RAG system for relevant context based on the query\n",
    "\n",
    "#     If no relevant context is found, return an empty string.\n",
    "#     \"\"\"\n",
    "#     # Placeholder implementation\n",
    "#     return context_rag.get_context_summary(\n",
    "#         query=query,\n",
    "#         workflow_id=\"agent\",\n",
    "#         stage_name=\"agent\",\n",
    "#         max_tokens=1000\n",
    "#     )\n",
    "\n",
    "class Context(BaseModel):\n",
    "    content: str = Field(..., description=\"The relevant context content\")\n",
    "    timestamp: Optional[str] = Field(None, description=\"The timestamp of the context\")\n",
    "    relevance_score: Optional[float] = Field(None, description=\"The relevance score of the context chunk\")\n",
    "\n",
    "@tool\n",
    "def search_current_knoweledge(query: str) -> list[Context]:\n",
    "    \"\"\"Query a RAG system for relevant context based on the query\n",
    "\n",
    "    If no relevant context is found, returns an empty list.\n",
    "    \"\"\"\n",
    "    # Placeholder implementation\n",
    "    context = context_rag.query_relevant_context(\n",
    "        query=query,\n",
    "        workflow_id=\"agent\",\n",
    "        stage_name=\"agent\",\n",
    "        n_results=5\n",
    "    )\n",
    "    return [\n",
    "        Context(\n",
    "            content=ctx['document'],\n",
    "            timestamp=ctx['metadata'].get('timestamp'),\n",
    "            relevance_score=1.0-ctx.get('distance', 1.0)\n",
    "        )\n",
    "        for ctx in context\n",
    "    ]\n",
    "\n",
    "@tool\n",
    "def store_knowledge(document: str, current_time: str) -> str:\n",
    "    \"\"\"Store useful information the user provide in the RAG system for future reference\n",
    "    along with the current time.\n",
    "    \"\"\"\n",
    "    context_rag.add_summary(\n",
    "        summary=f\"{document}\",\n",
    "        stage_name=\"agent\",\n",
    "        workflow_id=\"agent\",\n",
    "        metadata={\"time\": current_time}\n",
    "    )\n",
    "    return \"Document stored successfully.\"\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3:8b\",\n",
    "    base_url=\"http://100.91.155.118:11434\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools=[get_current_time, store_knowledge, search_current_knoweledge],\n",
    "    system_prompt=\"You are a helpful assistant that can provide and store information for the user\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a587fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 01:05:38.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_relevant_context\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1müîç Retrieved 1 relevant context chunks\u001b[0m\n",
      "\u001b[32m2025-11-23 01:05:38.387\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_context_summary\u001b[0m:\u001b[36m536\u001b[0m - \u001b[34m\u001b[1mAdding chunk (type=summary, stage=agent, size=62) to context\u001b[0m\n",
      "\u001b[32m2025-11-23 01:05:38.387\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_context_summary\u001b[0m:\u001b[36m552\u001b[0m - \u001b[34m\u001b[1mTotal context length: 62 characters\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n[SUMMARY - agent]\\nSummary for agent:\\nUser has a lunch scheduled tomorrow at 3pm.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_rag.get_context_summary(\n",
    "        query=\"Lunch\",\n",
    "        workflow_id=\"agent\",\n",
    "        stage_name=\"agent\",\n",
    "        max_tokens=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece76f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e44048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fa95e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 01:06:01.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_relevant_context\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1müîç Retrieved 1 relevant context chunks\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'document': 'Summary for agent:\\nUser has a lunch scheduled tomorrow at 3pm.',\n",
       "  'metadata': {'total_chunks': 1,\n",
       "   'stage_name': 'agent',\n",
       "   'chunk_size': 62,\n",
       "   'chunk_index': 0,\n",
       "   'timestamp': '2025-11-22T12:10:38.820197',\n",
       "   'workflow_id': 'agent',\n",
       "   'type': 'summary'},\n",
       "  'distance': 0.4513198137283325}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_rag.query_relevant_context(\n",
    "        query=\"Lunch\",\n",
    "        workflow_id=\"agent\",\n",
    "        stage_name=\"agent\",\n",
    "        n_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "266d8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Node model -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-22 12:10:38.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36madd_summary\u001b[0m:\u001b[36m402\u001b[0m - \u001b[1müìù Added summary to RAG: agent (1 chunks)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Finished Node-----\n",
      "----- Node tools -----\n",
      "Document stored successfully.\n",
      "-----Finished Node-----\n",
      "----- Node model -----\n",
      "I've noted your lunch appointment for tomorrow at 3pm. Let me know if you need help with anything else! üòä"
     ]
    }
   ],
   "source": [
    "first_node = None\n",
    "content = \"\"\n",
    "for token, metadata in agent.stream({\"messages\": [HumanMessage(content=\"I have a lunch tomorrow at 3pm do not forget!\")]}, stream_mode='messages'):\n",
    "    if first_node is None:\n",
    "        first_node = metadata['langgraph_node']\n",
    "        print(f\"----- Node {first_node} -----\")\n",
    "    this_node = metadata['langgraph_node']\n",
    "    if this_node != first_node:\n",
    "        first_node = this_node\n",
    "        print('\\n-----Finished Node-----')\n",
    "        print(f\"----- Node {first_node} -----\")\n",
    "        content = \"\"\n",
    "    content += token.content\n",
    "    if token.content:\n",
    "        print(token.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6459118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Node model -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-22 12:13:38.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mquery_relevant_context\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1müîç Retrieved 1 relevant context chunks\u001b[0m\n",
      "\u001b[32m2025-11-22 12:13:38.131\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_context_summary\u001b[0m:\u001b[36m536\u001b[0m - \u001b[34m\u001b[1mAdding chunk (type=summary, stage=agent, size=62) to context\u001b[0m\n",
      "\u001b[32m2025-11-22 12:13:38.131\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_context_summary\u001b[0m:\u001b[36m552\u001b[0m - \u001b[34m\u001b[1mTotal context length: 62 characters\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Finished Node-----\n",
      "----- Node tools -----\n",
      "\n",
      "[SUMMARY - agent]\n",
      "Summary for agent:\n",
      "User has a lunch scheduled tomorrow at 3pm.\n",
      "-----Finished Node-----\n",
      "----- Node model -----\n",
      "\n",
      "-----Finished Node-----\n",
      "----- Node tools -----\n",
      "2025-11-22 12:13:39\n",
      "-----Finished Node-----\n",
      "----- Node model -----\n",
      "The time between now (12:13 PM on November 22, 2025) and your lunch (3:00 PM on November 23, 2025) is **26 hours and 47 minutes**.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "first_node = None\n",
    "content = \"\"\n",
    "for token, metadata in agent.stream({\"messages\": [HumanMessage(content=\"How long between now and my lunch?\")]}, stream_mode='messages'):\n",
    "    if first_node is None:\n",
    "        first_node = metadata['langgraph_node']\n",
    "        print(f\"----- Node {first_node} -----\")\n",
    "    this_node = metadata['langgraph_node']\n",
    "    if this_node != first_node:\n",
    "        first_node = this_node\n",
    "        print('\\n-----Finished Node-----')\n",
    "        print(f\"----- Node {first_node} -----\")\n",
    "        content = \"\"\n",
    "    content += token.content\n",
    "    if token.content:\n",
    "        print(token.content, end='', flush=True)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd469e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-22 11:38:36.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mOutputCapturingExecutor initialized (timeout=300s)\u001b[0m\n",
      "\u001b[32m2025-11-22 11:38:36.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1müìÅ OutputManager initialized: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class Code(BaseModel):\n",
    "    code: str = Field(..., description=\"Python code to be executed\")\n",
    "    task: str = Field(..., description=\"Description of the task to be performed\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    code: str\n",
    "    user_query: str\n",
    "    input_data_path: str\n",
    "    stage_name: str\n",
    "    code_output: ExecutionResult\n",
    "    summary: str\n",
    "    graph_summaries: Annotated[List[str], operator.add]\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    graph_summary: str\n",
    "    graph_summaries: Annotated[List[str], operator.add]\n",
    "\n",
    "class ExecutionDeps(TypedDict):\n",
    "    executor: OutputCapturingExecutor\n",
    "    output_manager: OutputManager\n",
    "\n",
    "executor = OutputCapturingExecutor()\n",
    "output_mgr = OutputManager(workflow_id=\"test_workflow_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28614b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9b4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_code_for_task(state: State, runtime: Runtime[ExecutionDeps]) -> str:\n",
    "    code_llm = ChatOllama(\n",
    "        model=\"qwen3-coder:30b\",\n",
    "        temperature=0,\n",
    "        base_url=\"http://100.91.155.118:11434\")\n",
    "\n",
    "    structured_code_llm = code_llm.with_structured_output(Code)\n",
    "\n",
    "    input_data_path = Path(state[\"input_data_path\"])\n",
    "    user_query = state[\"user_query\"]\n",
    "\n",
    "    code = structured_code_llm.invoke([\n",
    "        SystemMessage(\n",
    "            content=f\"You are a helpful data science agent that writes Python code to perform data analysis tasks. Write Python code to load data from `{input_data_path.name}` and solve the users query. Any plots should be saved to files in the current working directory. Use pandas for data manipulation and any necessary libraries for analysis.\"),\n",
    "        HumanMessage(content=user_query),\n",
    "    ])\n",
    "    \n",
    "    return {'code': code.code}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab39f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data_to_execution_folder(state: State, runtime: Runtime[ExecutionDeps]) -> None:\n",
    "    stage_name = state[\"stage_name\"]\n",
    "    path = runtime.context[\"output_manager\"].get_stage_dir(stage_name)\n",
    "    execution_path = path / \"execution\"/ Path(state['input_data_path']).name\n",
    "    cp_data_to_folder(state[\"input_data_path\"], execution_path)\n",
    "    return {}\n",
    "\n",
    "def interpret_graph(state: GraphState, runtime: Runtime[ExecutionDeps]) -> str:\n",
    "    llm = ChatOllama(\n",
    "        model=\"gemma3:27b\",\n",
    "        temperature=0,\n",
    "        base_url=\"http://100.91.155.118:11434/\"\n",
    "    )\n",
    "    summary = llm.invoke([\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful data science agent that summarizes the results of code execution. Provide a detailed summary of the code execution results and the statistical findings. Justify your summary with the output and errors from the code execution.\"),\n",
    "        HumanMessage(\n",
    "            content=f\"The graph summary is: {state['graph_summary']}\")\n",
    "    ])\n",
    "    return {'graph_summary': summary.content}\n",
    "\n",
    "async def execute_code(state: State, runtime: Runtime[ExecutionDeps]) -> Any:\n",
    "    executor = runtime.context[\"executor\"]\n",
    "    output_manager = runtime.context[\"output_manager\"]\n",
    "    stage_name = state[\"stage_name\"]\n",
    "    code = state[\"code\"]\n",
    "\n",
    "    result = await executor.execute_with_output_manager(\n",
    "        code=code,\n",
    "        stage_name=stage_name,\n",
    "        output_manager=output_manager,\n",
    "        code_filename=\"code_with_data.py\"\n",
    "    )\n",
    "\n",
    "    return {'code_output': result}\n",
    "\n",
    "def code_fix(state: State, runtime: Runtime[ExecutionDeps]) -> str:\n",
    "    code_llm = ChatOllama(\n",
    "        model=\"qwen3-coder:30b\",\n",
    "        temperature=0,\n",
    "        base_url=\"http://100.91.155.118:11434\")\n",
    "    structured_code_llm = code_llm.with_structured_output(Code)\n",
    "    code = state[\"code\"]\n",
    "    error = state[\"code_output\"].error\n",
    "    output = state['code_output'].stdout\n",
    "    fixed_code = structured_code_llm.invoke([\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful data science agent that writes Python code. The following code has an error. Please fix the code to resolve the error.\"),\n",
    "        AIMessage(content=code),\n",
    "        HumanMessage(content=f\"The error message is: {error}, and current output is {output}\"),\n",
    "    ])\n",
    "    return {'code': fixed_code.code}\n",
    "\n",
    "def check_execution_success(state: State, runtime: Runtime[ExecutionDeps]) -> bool:\n",
    "    if state[\"code_output\"].success:\n",
    "        return \"SUCCESS\"\n",
    "    else:\n",
    "        return \"FAILURE\"\n",
    "\n",
    "def summarize_results(state: State, runtime: Runtime[ExecutionDeps]) -> str:\n",
    "    code_output = state[\"code_output\"]\n",
    "    \n",
    "    llm = ChatOllama(\n",
    "        model=\"gemma3:27b\",\n",
    "        temperature=0,\n",
    "        base_url=\"http://100.91.155.118:11434/\"\n",
    "    )\n",
    "    summary = llm.invoke([\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful data science agent that summarizes the results of code execution. Provide a detailed summary of the code execution results and the statistical findings. Justify your summary with the output and errors from the code execution.\"),\n",
    "        HumanMessage(\n",
    "            content=f\"The code was executed with the following output:\\n\\n{code_output.stdout}\\n\\nAnd the following error (if any):\\n\\n{code_output.error}\")\n",
    "    ])\n",
    "    return {'summary': summary.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba2e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAIrCAIAAAA7mSZWAAAQAElEQVR4nOydB0DUyBrHJ9mld1BQESn2jr2cvfd+Z++e3bPf2bueDfXseufZey9nefbeFbE3QAREUaSXbXnfbmBdlgVB2N1s8v2ej0smk0k2mfnPN99MZsQMwxAEQYSKmCAIImBQAhBE0KAEIIigQQlAEEGDEoAgggYlAEEEDUpAdklJIv4Xv34MSU5OlMtkCmmSqjOVIgT+SzGEgS1CmxGFVBWbJkTBnsfANkVRjFydkuoEiqEp5SmMglC08i8LBafRNOyqUqRST4DoFEXUcWCTUVCEhhPZFFKhGZqmFLJv9yy2pMUiysyadi1kWaG2g72riCBIeigcF/BdDq0J+/Q+WSZhzMxpC2va3FxEi4kkSVWmoTjCA6SVhRL2xGa0TKoskd9KNaWUA2WJV6Q9Z5VqQJmmVQUcwmHr21FRamSlAKjfDKRANOLQyrcGRymR8upqCYDyDzEVsm8v1MxKBLuSFCJJlEkkCpGYOOU3bzXQ3cEFtQBJBSUgK3YtDomKkFjbiYtXsqvbwYWYOHdOf312OyYuWmrnZNZvhhdBEJSAzLhxIsr/0leHfGbdxhURmROesX9FaMS7pGLl7VsOcCOIsEEJ0MFev9CYz5KOwwrnL8K70q/BP9OCxWZUv5meBBEwKAHanN8VGRqY2HeaIArGgeXhMpm820QPgggVlIB07FwUIkth+s4QUMV4YHlYzBfpwHleBBEkNEHSOLbhgzRZWOUf6DLW3c5ZDNpHEEGCEpBKyIvk0DdJwmwY/zKucEKM7PqRKIIID5SAVE5uDi9f24EIlVb93f2vogQIEZQAJZcPfKbFVN2OJt/z/8MULm5h52R2aFU4QQQGSoCSZ3djS/raEWFTt4Prh3eJBBEYKAHgBUhRyBT1f85HDMi+fftmzpxJcs6kSZOOHj1K9IB3OSuRiLp66DNBhARKALl79outo6GHAD179oz8ED98YnYo4GkV/AINAWGB4wLIP9OCPErYNO/jSvRAcHDw+vXr79+/D8+5QoUKffr08fX1HTx48IMHD9gIO3bsKFWq1N69e69evfrkyRMLC4vKlSuPGDGicOHCcPT3338XiUQFCxbctm3b4sWLYZc9y9bW9tKlSySveXw97tqRT8OWFCWIYEArgEhTFMUr2BI9IJFIoLRDGV61atW6devEYvHYsWOTk5M3btxYrly51q1b37t3D8q/v7//kiVLKlasuHTp0tmzZ0dFRU2bNo1NwczM7I2KZcuWVapU6fr16xA4ffp0fZR/oPxPdgocKSYwcL4AolAwPuWtiR549+4dlOfu3btDOYfdhQsXQuUvk8m0opUvXx5cA0WKFAGNgF2pVApKERMT4+DgQFFUeHj49u3bLS0t4VBKSgrRMzRNBT1K9q5oSRBhIHQJiGf7wvXz+TyUaicnp1mzZrVq1apKlSpQz1etWjVjNDATQkND/fz8oCGQkJDABoJ2gATAhre3N1v+DQSt+Pox2ZugBAgFoTcEFLQeDV9o2P/999916tTZtWvXwIEDO3TocPLkyYzRLl++PG7cuDJlykDku3fvrl69WisRYkAoQikIIiCELgH2jpReG79eXl5jxow5ceIENOaLFSs2Y8aMFy9eaMU5fPgw+AjBBViiRAmw/OPi4ojxYBSUfT4zgggGdAcq672QF8lED0B3wLFjx2ADLPl69eotWrQIWvvPnz/XigbNflfXb/0RFy5cIMZDLlN4lrYhiGBACSBmFvSbgHiiB6Bsz5kzZ8WKFe/fvwfX4ObNm8EXCB4BOOTh4QEtfzD7oc0Plf+tW7egdwCO7ty5kz33w4cPGROERgGIhToyyWteP0wQiSgLK4IIB5QAYusgevdcLxIApX3KlCmnTp3q2LFj586dHz58uH79eh8fHzjUqVMnsPnB+H/9+vXw4cNr164N7oBatWpFRERAvyD4BX777bfTp09nTHPAgAEgHOPHj09KSiJ5zfNbMRbWOLOosMChQeTpzbiLBz6O9CtGBM/GKYGepW2b99bLKCmEm6AVQMrWsiMMuXNG6J/KxkTKpRIFln+hgUODlHiUtH54Mbp6c+fMIoDF/vTp04zhcrkczCh2SE9Gjhw54ujoSPRDgwYNdIZnfUvnzp3L7NCpreHOrnyeLhXRCTYEUlk97k29zq4VfrLXefTz588SiUTnoZSUlMy67gsVKkT0Rnh4pt/2/8AtSSVk/R9vRi3H1pDgQCsglapNna8dicxMAvLlM+inxNkhb/Vly9wgzzJ6+VAC4TjoC0ilZktnp/zme/1CifA4uSmCYki7XwsQRHigBHyj++8ecdHSI2s/ECFx70xMyKvEQfO8CSJI0Begza5F780tRV1G67EZzx0u7Il8GxD/6wIs/8IFJUAHm2cFUzTh/cKbIHZxX6VDFvoQRMCgBOjm4OrwiKBEnwr2LfvysJ/82uHP/teiHVzMe08pQhBhgxKQKR9DJCf+DpMkK1wKWNTv4ubmafLfz8VHK87tjgh7kygS07Vau1SsJ9x1ExA1KAHf4eXdhOv/RSbHywlFrGxFtg5m1nYisblIkizVjAYNB0aR+lcNDbsMRVGMQiOQIoQh2jEpVUw6fUyaphQKBhJJdzqtTIAi6QJJhgRZzC1ohqETYmXx0VL4BxEsbUUVfnKo3iLTQVCI0EAJyC7+l6KDnyfFRUmlEgWjYCQp6Z4bRUEZTv2rGciWd61AHTGhSKtKMEXRP5AmSVMWLcRmlNicFouJjb24oI9VrdZY8hFtUAK4wq5duyIiIsaNG0cQxIDg6ECuIJPJMhu9jyD6A/McV0AJQIwC5jmugBKAGAUcIMwVUAIQo4B5jiugBCBGAfMcV0AJQIwC5jmugBKAGAXMc1xBKpWameEaHoihQQngCmgFIEYB8xxXQAlAjALmOa6AEoAYBcxzXAElADEKmOe4AroDEaOAEsAV0ApAjALmOa6AEoAYBcxzXAElADEKmOe4AkgA+gIQw4MSwBXQCkCMAuY5roASgBgFzHNcASUAMQqY57gCSgBiFDDPcQWpVIoSgBgezHNcAa0AxChgnuMKbm5uNI1TOSKGBiWAK0RGRoIhQBDEsKAEcAVoBaAEIIYHJYAroAQgRgElgCugBCBGASWAK6AEIEYBJYAroAQgRgElgCugBCBGASWAK6AEIEYBJYAroAQgRgElgCugBCBGASWAK6AEIEYBJYAroAQgRgElgCugBCBGASWAK6AEIEYBJYAroAQgRgElgCugBCBGASWAK6AEIEaBYhiGIMajefPmkZGR8BZomqYoSqHCy8vryJEjBEH0D85UZWSaNWsGJV8kEsFf2AUhsLCw6NGjB0EQg4ASYGR69epVuHBhzZAiRYq0b9+eIIhBQAkwMm5ubi1atFDvgi3QsmVLMAQIghgElADjA2a/h4cHuw0WQefOnQmCGAqUAOPj4ODQpk0b1h3QtGlT2CUIYiiE2CPw9lFS0JP4pEQpu0vRRERTMpnyOYBXXqFgRGIil8E2USgIQxEomvBfomAjK712DJP22GhVNHVfHqVKQf7tkariMwqFehdMfaKQE80I8Fcuk99/cB8u7VuxoqWVJaNgIFjBkPTpwP0wRHl5jdSUgel+XcYrMuydiyhGnuFdU8rfLpfrzgOW1mL3YrZlalgThL8ITALkZNPsd9IUmZm5SJKsLiVQbhmFXFkUlVaRglBiigFFUG0zFKMqU4R9ThTFKP/PpJZDimYoilaXeUaZFGE0SzilTJ9Rl1IK4lOMRqFVpq98C4T9H9svwJ6Y7s3AhYjqRA0JyJjatzvMIAGQAlFQWs8DUlP+mozhKsytRFKJAn5R054FvMtaEYSPCEgC5HKycUpgyUpO1Vo6ESTbPLsR9+BiZK9JnnbOIoLwDgFJwPpJQT+1cvOqiGZtjpFLyK7FgcOX+BCEdwjFHfi/HZHm5iIs/z+GyJw4OZvvXxFGEN4hFAn49D7JPh9+EPHj5CtiGftFShDeIRQJSElU4LcQucHMkkpJkROEdwilYpTJFXKpgiA/jJxRyPAB8hC0jZFsoeqvpAjCO1ACkGzBEGxI8ROhSICyAsPB0LlAaQKgEcBHhCIBytEP2JLNFYxy8CPCO7AhgGQPRnNkMsIfhCIBNK0cLY/kDrQCeIhwrADMvrmCIQRnmeQlgvEFKD/6I8gPo/QG0vgEeYhgrACGwvybGxh0B/IUIfUIoAbkAgrdgTwFewSQ7IKjg3iJULzkymU69PxbAwPfNGxcNSDgIeEG0dFf4X4uXjpL8gLlpEU4QJiPCEUCFAzD6HlokKOjU5/eg1xdC8B2UNDbbj3aEB5BYUuKp2BDIM9wdnbp328ou/3y1TPCL9ipEgnCO4RiBeT0G4FOXZpt3fY3ux0TEw0W9ew5k9RHu/zSYveerQcP7en8c/Nr1y81blp91Zql6obA5i3rFy2e/fFjBOzuP7AT4kdFfZk3fyrYBR06NZn/5/T3799l5x5CQoJHj/0VEunZq/36DX9JJBJ1+LjxQ9u0q9++Y2OI8ND/nvqU8xfO9OrdoV2HRgsXz/r6NUoztdNnjg8f2a9l6zrw98DBXTmdME5V+tEM4CFCkYCcfiNQtWrNZ88fs9sPHt51cyvw+Ik/uxsWHvrly2eIYG5unpiYcOzYgcmT5nRs/4v6XLAFunXtA6dcPH/v5y495XL52PFD/B/dHztmyr//7HVydB4+oi8kkvUNRER8GDmqf/lyvn5L13Xt2uf8hdMrVy2GcCjYEA7NjY0bdq1ZtRlSmztvSmJiIlE5I+YvmNasWZsd2480b9Zm1eol6tTOnT8NqlSieKldO44NGjgCJGD1Wj+SI5QagBLAQwRjBZCc+bIqV6r25Ik/W1U+enS/Qf2m8fFxbLl9/PghNPuLFysJ7rHk5ORu3fo2adyicOEimSX1+LE/1NtTJs+tUb02NBaGDR1j7+B48OCurG8ASqmFpSWoCdxJu7adBw4YbmZmBuFgVphbWEwYP61QQXe46MQJM5KSEo8e2w+H4K+bawHwR9jb2Vfyrdq6dUd1aidPHqlQodKY0ZOcnJwhwf59hx45sg+sG5J90B3IUwQjATSTox6BKpVrQNUKXj3YhvofauNSpco+eaw0BKBIV6lcXR2zVMmyWScFp0PphYKXeicU5VuxyqOAB1mfFRj4unjxUiJR6rzdLZq3Hf3bH8rwoDcQLhanOnFsbGw8Cnu+evUctsPC3nt5F/12Y6VSb0yhUDx5+qha1VrqQ5UqVYPA58+fkOyjIJktN4CYNEJxByoU2qvuZE3+/K4eHp5Qclxc8oEQQJl5/uIJFObmzdsEPH4Idr46JjQHsk4KzAepVApNes1AsCOyPishIV5nnKgvn93dPTRDLK2sEpOUDYHY2BhNY8TKMnXxD3AiwA1s+nct/NM8MUdWgHJQAA4Q5iPYI5ApUNWDOwDKoY9PMWtr6/LlK61bvxyKTWhoSK2adbOfDoiIlZXV/HnLNQNFF482QwAAEABJREFU9HeW5bCxsU1ITMgYbm1jk5ySrBmSlJhY2F1Z8u3tHTQPJaadbmlpCfffrGnrevUaa54I5gPJNsoJQ1AB+AhKQKZUrlx93brltjZ2FStWgV1oC0CT/ty5U0WKeEGTPvvpFC1aIikpCRx47oUKsyHhH8IcHb5jBZQsWeb4iYMymYy1+cHVf+rU0UULV5UsUebM/05Arc66BmLjYt+FBDVr1poo1ykveOPmFbDwaVrZ5rl566rmPcTFx4GDgN2F0z98CANtItmGwU+teYqAOgVzOjqwkm+1iI8fbt68Uq5sRdiFihRcgIcO76lSpcZ3zwWDHHoNrl27BP1/YE1Ur1576dK50E0IRsSRo/uHDut9+vSxrFNo3aoDGPDLli+4d//21WsX//5nlUu+/OAaaNu2M7QR/JbNh9SCgwP/XDjD0sKyVcsOcEqDBk2jo79CRwB4MaGnEBx+6tR+HTjy+vVLJ08dBYEAX8acuZPHTRgKQkCyDUUIegN5iXB6BHJsxtra2kJVDDW22pNXtmwFzd0sqFmjDlgN02dOgNobdv+cv6J+/SZz5k3u0KkJiEiTJi07deqWdQogIgv/XOnvf2/i7yOgq69G9Z9GjpigDHf3mDljYVDQm2492owZNxhC/lrxDzgFYaNa1ZpDh4y+c+dGoybVFi2eNemP2US1CDL8LV/ed+P6nQEBDzt2bjrh9+EgIvPmLvuuFyMdCpwvgJ8IZU3BDVMCHVzMWw8qTJAf4t7Zz89uRo/wK0YQfiGgicNwBuFcgT2CPEVAnYJcm0F41+4tu3dv0XnI08tn9cp/CYLoH6FIgFhMiUTcqsfAsdewYTOdh8Qizr0XSgT+VDQEeIhQJEAuY+RybpkBdrZ28I+YCIyCYXBlVj4imNWEaHAHYCWWC3DiQJ6CA4SRbIGTiPMVXEoEyRY4NIivCGgGYazEcgWFkwbxE+F8I8BgDs4VOHcgTxHQUiKYg3MFzh/KU4SzoBhm4NzBYEuAnwjGHUjhAGEE0YFgOgUZzg0QRhAuIBQJMLekzS3QDPhxKBExsxQRhHcIRQJs7MRJ8WgG/DhxX2SoobxEKC+1amOXuK8SgvwoH98nepaxIQjvEIoE+FSwcsxvccDvPUFyzrE1YbYOZg275GCuQcRUEMqsQSzn934OehxfsKiNZwkbqUymMw5FpX8maVOOZQinUscbqjc0Zyej2LFIlOaC3JQqpvbjhr4KrS/wKNX/mfQnEt0X17pn5fWotOumRcrszjNOpqYVU0SLI0KSQl/FiUVUnxk5mG4YMSGEJQHAzRNRL+7FSpIV0pRMXANsyUgrH0y2e8N1xMzGjIVahZk9S1mQNb/Mo9IukGkq6Y9SaYP5qKwiM0yGYf/p0xGZUeYWIo+SNs165ScITxGcBHCW3bt3h4eHjx8/niCIAcF1BLiCeskABDEkmOe4AkoAYhQwz3EF9QJBCGJIcLAHV5DL5WgFIIYHJYArYEMAMQqY57gCSgBiFDDPcQWUAMQoYJ7jCuAORAlADA/mOa6AVgBiFDDPcQWUAMQoYJ7jCigBiFHAPMcVcGgQYhRQArgCWgGIUcA8xxVQAhCjgHmOK6AEIEYB8xxXQAlAjALmOa6A7kDEKKAEcAW0AhCjgHmOK6AEIEYB8xxXQAlAjALmOa4AEoC+AMTwoARwBbQCEKOAeY4roAQgRgHzHFcoVqwYSgBieDDPcYU3b95IpVKCIIYFJYArgAkgy2SZQwTRHygBXAElADEKKAFcASUAMQooAVwBJQAxCigBXAElADEKKAFcASUAMQooAVwBJQAxCigBXAElADEKKAFcASUAMQooAVwBJQAxCigBXAElADEKKAFcASUAMQooAVwBJQAxCigBXMHMzAy/FEQMD0oAV0ArADEKKAFcASUAMQoUwzAEMR6NGjWKjo6Gt0CpgBCFQlG4cOHjx48TBNE/NEGMSp06daDki0QimqZZFYDttm3bEgQxCCgBRqZ3794eHh6aIZ6enh07diQIYhBQAoxM8eLFa9SowTYBANioV69e/vz5CYIYBJQA49OrVy9vb292G0yADh06EAQxFCgBxgcaAj/99BO4AGC7Vq1aoAIEQQyFEDsFg5+nJMenZCcmmOXZ6jGhKaL4bjSlsZ9ZarXLd3lTKkEilVYp1f7F/XjoFcgqIUIYms46DlHFobKOQyn/l/UPtLCw8K5gQRD+IqxOwf3LQr9ESGBDJlVkJ76q0GYjGk0x35MARikU2XjaDKT2nYvCUZr+/o199+ZVt/SdOGIzWsEwDs7mPSd7EISPCEgC9iwOk0oV9Tq6ObubEyTbSBLIuT0f4qJSBs3zIgjvEIoEbJ0XYmklbjWoEEF+iDsnvwY+jfkVVYB3CMId+PJOQnKcDMt/bqjeyommmYt7vhCEXwhCAp7ejbV2QOM/tzi6WoW+SSAIvxCEBCTGSWkRQXKJ2IJJScHPmfmGIDoF5Sng8MCP8HKLXKKQZqsvFTEl8GNhJPswFEH4hiAkgFI2dzD35hqKonA0Ke8QxCtlCM6JkAdQKKN8RBgNAQWFKpB7GOUYElQBvoG+ACS7MEoRyNbAasSEEIYvQIRGbB5AKQeT4mPkG8KwAhh0B+QBFE3TYpQAviEICQDrFQUg9zAKhUKGD5JvoC8AyS7Kyc2wU5B3oAQg2UX5TSl6A3mHUIYGYW9W7qHFIpEZPka+IYyhQSAA/GrDrvhrYf+BvxDDopDJ5VL0BfANYbTtGCLMRZNmz5l08tRRkmfQOECYfwjjldKMcpY84fHy5TOSlyhwZBD/EMoAYZLDbsEOnZr06zskNDTk4KHdjo5OtWrWHTliwoKF069fv+zh4dmrx4BmzVqzMSFk67aN70KCHBwcixUrOXrUH25uBf7ZtObwkb1HDp03MzNjo+3Zu23Tv2uPHr5gbW19+szxY8cPBgW98fYu1qhhs86duquXEsmMxMTE+X9Oe/jwLpzSvm0XzUNBQW+PHT/w4OHdiIhwL0+fVq06tG+njNCwcVX4u2Tp3HXrlx8/eik+Pn7/gR137t4MDn7r4pyvdu36A/oPs7S0JNlG+ZWQIJWU3wjDCqBybAVA0d2zd2uRIl5nTt0YNHDEqdPHxo4b3LhRi7NnbjVs0HSJ39y4+DiIdu/+7RmzJoIc7Ntzcub0hR8/flixciGEN2zQDArtnTs31AlevXYRdATK/7nzpxctnl2ieKldO45BygcO7lq91u+797PUby7o0dIl6+bOXhoU/PbW7WvqQ2vW+t29e3P0b38s/HMllP+/Vi66dfs6hJ8+qfw7ccJ0KP+wcejwnl27t3T9pfeC+SuGDBl96fJZUC6SI5hsTJWOmBqCkABKDNUXySnFi5Vq17azubl5g/pNYbds2QpQ+MViMRRvmUwW8i4IAv/dvK5e3UZdOvcAEwAiDB827tatay9ePitatHihQoWh2LNJffny+dmzx40aNYftkyePVKhQaczoSU5OzpUrVevfd+iRI/u+fo3K4k4+f468eOls9259y5Qu5+zsMmTwbxYW32rv6dP/XLJkLSRVybcq1P8lS5S+c/dGxkR++bnXPxt3N6jfBKLVrdMQfoXOaFmgGmOJGsA3hNEjICU/MKwNTAB2w8bGBv56eRVld62srOFvXFws/A0MfF2qVFn1KSVLlIG/L148hb9Nm7S8eu2CXC6H7StXL1hZWdX5qYFCoXjy9FG1qrXUp1SqVA0CAx4/zOJOPnwII8q1xny+XahkmW+HGebQoT19+nUGyx/+gQBF6xIUsGvu3rs5bHifps1rQrR9+3dkrTu6+G57BTE9hDFA+Ie+FdbK73QGQwJa1ykpKZoVMtj5RNluV86x2aRxy63b/oYmerWqNa9du1i3biOwIJKTk6VSKTgF4J9mUlmXxpjYaGXiKulhsbK0YjdAPiZNGS2VSn4dNNLXt6qdrd2o0QN1JrLx71VggEATAASI9VbkvLNAmP0qPEcYQ4MYvcwXwPrSkpOT1CEJqsIPzjb4W7hwEWgOXL9+qUSJ0v6P7kNDnT0FZKJZ09b16jXWTKpQwcJZXMjB3lF5oZRkdQirMsCr1y/A6Fi6ZG2VytXZkPj4uPz5XLVSgLJ7/MRBaLC0ad1RHY3kEBBBWoRmAN8QzsRheQ/U6tDwfvo0QB3CbvsULc7uQnv7xIlDYMDb2ztAW50NLFq0BLgSoUHO7oJRAHa+q6tbFhcqUEC5AsKTJ4/gcuwp4IaEfgrYjolRGgjqMh8cHAj/vNPaLGrglKSkpHxp0SQSyY2bV0gOUTCMAv2BvEMg4wKUy/4RPdCxQ9dr1y8dPLg7Ni72of+9teuWQVEvXqwke7RBg6YRHz+cPn2sYcNm7MLBwK8DR4JpAEY42PCPH/vPmTt53IShUCazuEr+/K7lylXcsmX9+/fvoOkxb/5UdSMFegFBifbu2w43EBISvGr1Emh3wEWJakVQOPHevVtwY1B/g2sD+jXCwkNBNRYvnVO+nC+4MxIScrIuAIOfXPMQYbgDZURPX7lCd+DAAcP37t/evkOjRYtnVShfacb0P9VH3QsVhnobbPXGDZurA8uX9924fmdAwMOOnZtO+H14QkL8vLnLoLhmfaHJk+aULl1u8NCerdvWs7Ozb9WyPdsuh1b91Cnznj1/DDcwZdpY6GVs167L8+dP+vZXDg3o2WMAOCOmzxiflJw0feoCSwvLfv279OrTAVoNgwaNhN3OPzcjiLARxJqCW+cGw4/s/JsXQXLB2R1hke9Thiz0IQiPwNGBSHahsEuAjwijU5DzcweCU2DK1DGZHd2x/YiDgyMxNgxBIeUhwrAC5FyfO1DpINi4K7OjXCj/SiicdYGHCEMClBPfcj3zFizA+bXPGbQCeAgODUIQQSMMK4BmaBzdnnsoCj8S4B9C6RHAacRzj7L882wCNkQoDQExurHyAOXwYJw1iHcIo1NQhjYAguhGIL4A5eyBSC6hcL4APiKMhgA7PhDJHUKdh5nnCGVNQQRBdCKQdQQYBl3ZCKILQVgB5la0AvsEco25hdjcSkYQfiEIK8DKTizDlbByTVICY26JywnxDUG80coN8iXFY/WVW2I+pXiVtCUIvxCEBBQpY+7gbHZk1XuC/Cjnt3+kxVSdTs4E4ReCmDWI5fjfEZ9DU8rVdi5V044g2SbkWeLDi18gm/Se6kEQ3iEgCQBO/B0RFpgolzIKeVb9hAyhqJyPJ8zsLIZk4opkdAy5zxg5Y7IKwtDpYmnNiZRuN0OC345qpqxQTrPMZIxDiWiRiMrnbtHlN3eC8BFhSQCLPInEx8t1H6PSSgaj80iGXY3QdBHYdNLH0Z69jC2aaUGnT5/8+PFTv779mIxXIuliMjRDaQx1olRikno0Q2Stq5A02WHS/wSNQk80v6w2NxdZORCExwhjgHB6RFbEwUpEOIaERDNm8fb5OXdjCL8RogRwE5lMJhbj60AMDeY5riCVSs3MzAiCGAVmEzAAABAASURBVBYc6cEV5HI5WgGI4UEJ4ApgBaAEIIYH8xxXUCgUGdcvRxB9gxLAFdAdiBgFzHNcASUAMQqY57gCSgBiFDDPcQXsFESMAkoAV0ArADEKmOe4AkoAYhQwz3EFlADEKGCe4wroC0CMAkoAV0ArADEKmOe4AkoAYhQwz3EFlADEKGCe4wroC0CMAkoAV0ArADEKmOe4AkoAYhQwz3EFlADEKGCe4wogAegLQAwPSgBXQCsAMQqY57hCiRIlzM3NCYIYFpQArvDy5UvoFyQIYlhQArgCtAKgLUAQxLCgBHAFlADEKKAEcAWUAMQooARwBZQAxCigBHAFlADEKKAEcAWUAMQooARwBZQAxCigBHAFkUiEEoAYHpQArmBmZoZDgxDDgxLAFbAhgBgFlACugBKAGAWUAK6AEoAYBZQAroASgBgFlACugBKAGAWUAK6AEoAYBZQAroASgBgFimEYghiPSpUq0TStGQJvxMXF5ezZswRB9A9NEKNSs2ZNKPOUBhDYqFEjgiAGASXAyAwaNChfvnyaIe7u7l27diUIYhBQAoxMlSpVypUrpxkCTQMfHx+CIAYBJcD4DBgwwM3Njd0uUKBAt27dCIIYCpQA4wNWANT87Hbp0qXLlClDEMRQoARwgr59+7q6ukJHQPfu3QmCGBC+dQoeXvPhc2iyVKaQyzL9XawHXjMAnkMWaeo4nL0gShWaa7K4ve/cub4umwYtosRiyiGfebcJhQlimvBKArYveMfIqdLVnTzL2hGF/NsBKPDqn8kWfs1frc7ojEaI5lOhaMIo0l2JpoiCSRdN8xIkQzrqoxmvrpmgjhPT31jGo8y3XYaC15nhfrR++7fbYNL/Rq2fnHbhLOIQIiKisHcJz25/jYuS/rrAmyAmCH8k4N/p7xxcLZr1KUAQg/PsVrz/xcghC1EFTA+e+ALO74qEOgrLv7EoU9PWxsFs/8pwgpgaPJGA968T8xW2IojxKFrB7mtEMkFMDZ58JiSVKmwd8JMnY+JUwEouwe9NTA++SECyQiLBuTeNiZyRyOQoAaYH1pwIImhQAhBE0PBEAqAbm9LbGBkE4TE8kQCGITj1CYL8ANgQQBBBwxcJwIYAgvwQ2BBAEEHDF3cgQRDkR0BfAJI3UAzqsEmCvgAkb2AobImZJHyRAPQFIMgPgUODEETQ8ORjYbQAfoDo6K8NG1e9eAmXLRI0fJk+1AQbAh07Nw3/EEYQxKhgj4BxiIj4AJUwQRBjI9wegaioL2vXLXvy9FFycnK1arX69Brk4eEJ4Uv95t29d3Pr5oOWlpawu3PX5h07N/27aV/BAoUyOwUICQn2Wz4/IOBhoYLudes2GtB/mLm5+Z6927Zu23jqv2tsnI8fI7r1aDNvjp+1jc248UMhpGev9j/9VB9CZDLZpn/X3rp97dOniHLlfDu2/6VmzTrf/QmxcbEbNvx18tRRBwfHqlVq/DpolJubcuq0xMTEZSsW+Pvfi4uL9fL0admyfYf2P7OnnL9wZvPmdXBi7dr1uv7cWzO1p08D4G5fvHjq4OhUq2bdvn0G29jYEITvCHQdAblcPnb8EP9H98eOmfLvP3udHJ2Hj+gbFh4Kh4YMGS2VSrdt/xu2P3+OhPI/Yvh4KP9ZnAJV+shR/cuX8/Vbuq5r1z7nL5xeuWpxFlev5Fv1z/krYGPnjqNQ/mED4h84uKtjh667dh6vX6/xzNm/X75yPuufAKoxafJvn79ELvNbP2rkxE+RHydN+Y1dnhw2wsND587x27fnZL16jf9auej5i6cQHhj4Zv6Cac2atdmx/UjzZm1WrV6iTi007P2E34cnpySvXrV57uylgYGvx44bjIudCwGB+gIeP/aHenvK5Lk1qtd2dnYZNnSMvYPjwYO74JCdrR2UqP0HdkLxXrPWr3Spcm1ad8z6FCi9FpaW/fsNrVypWru2nQcOGG5mZpb9m0lJSTnzvxM9uveDcx3sHVq1bN+4UQtWg7IATIbnz5+MGDYOBKVxo+YjR0woWrQE2Cm3bl+HW504fnrpUmXBOujZo3/58r5QvcMpR4/td3Mt0Kf3IHs7ezirtep3sZw7d8pMbAaFv0gRLy8vnwnjp79+8/La9UskB1A4SNMU4Y8VkKPs9/iJP5RSKLGp51KUb8UqjwIesLsNGzStWrXmlKlj7ty9AWX+u6dAnVm8eCmRSMQeatG87ejf/iDZ5tWr5xKJpFrVWuoQSBlq7JjYmCzOevv2tbW1NZRYdrdE8VLTpsxzdXULCnoDTRhv76LqmCWKl3758hlshIW999IIL1WqrHr76dNHpVSSwe4WKFCwUKHCAY8fkmxDwxvAjhkThD/uwBxlv/j4OLD2oUtMM9DR0Um93bN7/1GjB0JRzJcv/3dPSUiI1zw3p0DK8BcupxX+NeoLGAWZnQUXtbCwzBj+5ctnS8t0kymDUiQlJcJGbGxM4cJF1OFWGtHgHl68fKb16+AGSLZREAVBTBAeuQNzYge4uOSzsrKaP2+5ZqCIFqm3N29ZX+enBmBsQ7c5GAVZn2JjY5uQmPDdi8o1FzjSvBmVyowfN9Xd3UMz3NU1q2URrK1toGArFAqaTmfKgQ8vOTlJMwTuLZ+L8hL29g7Q2leHJ2rcs7NLPmgvQFtG80QHe0eC8B3+fClI5WSMOjSbk5KSoIy5F0pdDA+66B0dUmvyE/8dfhv4euf2o/v2bwefGTQKwEGQxSklS5Y5fuIgOM/EYuXzBK/7qVNHFy1cZWZmDu18dXjIuyCdN1PYvYiFhQVRuQnZkK9foxiGgdo7i59QqmQZ6Jh4+ep5aZU9D34K6AUYNWJiyRLKcGjJFy9Wko0JLgPW/ndzK3jj5hW1aty8dfXbA/Ep/r+z/1WsUFktKMHBgZomA8JX+DI6MIfuwCqVq1evXnvp0rnQURcTE33k6P6hw3qfPn0MDkVGfgIv4LAhY6A67dljAFjLa9cuy/qU1q06QGN+2fIF9+7fvnrt4t//rIKKHVwDZcqUh5J8+sxxouoR3LVni/oGPFRt+EuXzj57/gSKer++Q8D/B248SAf6AsA5v+KvhVn/BBAmsBo2blwJV7x77xbEj/z00dPTG24SmvHLls0Hwx68g9DXCBLA9v81aNA0OvoriBrc1UP/e0eO7FOn1qVLT5CG1Wv9QD7ev3+3YePKAYO6Bga9IQjf4cmagmsnvPWpaPtTO7fsnwI5/tjxg2fPnXz27DF070OJ+m3kRAiHHnuJVLJ65b9stAcP746fMGy53wZf3yqZncJGA3X4EBEO9Tn0tw0aNBIMBwjft3/Hjh2b4uLjQA4GDxo1Ztxg8LrXqdMADi1aPPvc+VPlylZcvmwD7EIxPnR4z4MHd6BZUbZMhQkTpmfhCGCBzsg/F80ICFA67WrVqjt08GjWOxgU9Hb9hhWQoLm5uY9PcehrgEYNe8refduPHTsA9oubW4Gpk+f9NmbQ9GkLGjVsBofgJvfs2Qq9AGBQgGsQuidatmhHsk3I6/gLOyNGLS9GEJNCuBKA5C0oASYKjwYI46eCCJJzeCQBvJswYNfuLbt3b9F5yNPLR91UQZDcwJ9OQf7RuVP3tm076zzExYF4FE7haJLwZ9Yg/mGhgpgIFEOjApgi/GkIYP4zLgxR4Nxtpgh/GgKY/RDkB8CGAIIIGv5YAbRApz5AkFzBo0nE8UM1BMk5POoURH8gguQcXEoEQQQNj6YMQSsAQXIOTySANqNEIvQHGhMxMaNxcJAJwhMJsDATKSQoAcZEkiQXm6MEmB48KTZOBcw/vf/+1F2I/njlH2NjhyvTmB48kYAOwwsmxski30sIYiQiQ5NaD8SJxkwPnkwZAkgk5N+pb30q2Ndql58gBuTRxa9Prkd1GlnE1TMHqycgHIE/EkCUawSRrXOCUxIVIjGRpmj8Lkp7BDEtIlrT+VIihpGnNmUpStXFSOkad6wO1DzKbmeMny4ykzp0IeOJGSJDFyel7uHQeUX1IVVcrUBK5+QJlCpmZqml22XSUiHfnoauGxBbUPAYzcyppt3dPcuaE8QE4ZUEsMREkNcBXyUpGkVchwTQCnm64YQUrTG+UBWfopQPJyws7JH/o1atW6VFoxiFVslQb2a4jPqAcnpjRrtEkdRLsNv379+PjY1r2LCBdhnOWBS/Ja+KqBWoCtf8ai+don2TgHTJKZNS3yI49hUMhGzZsqVmzZqlSpVkdJ0CmJmLCvlYuxc3mS+akYzwUALyltWrV48cOZLomejo6EGDBkml0lWrVhUpwqEW9fHjx9u2bfv06dOyZcsShI9gR5puoE5et24dbBig/AN79+4NDQ0Fi2PHjh2ES0D5J6pVWGvVqhUcHEwQ3oESoIPExMSNGzdCtUwMQmRk5OnTp9llfO/evQtCQDhGhQoVrly5AkYKbB85coQgPAIlIB0hISEBAQE0TW/YsCFHqwPnhj179rx//57dBlvg8OHDhHvA0yhevDhsREVFde7cmSB8ASXgG4GBgWPGjClZsqSlpSUxFB8+fDh//rx6F1wzsPvx40fCVQYMGLBt2zbYuHHjxv79+wli4qAEKElJSYG/SUlJhw4dMvCMndu3bwfTQzMELIKDBw8SDmNjYwN/q1evDqK5b98+gpgy2CNAwN09ZMiQa9euEWPQokULqPOh6cG+CPgLvXEFCxb877//iCkAumllZTVp0qTatWu3a5eDBcgQjoASQKAe++WXX4ixWblypaOjY58+fYgJ8vXrV+jOnDx5cnJysp2dHUFMB+E2BJ48efLHH3/ABhfKP1F1vLFrkJsiTk5OM2bMgPuPj4//+eefX758SRATQbgSsGnTptmzZxPOABJAm/gUqGwTZvHixc+ePYNdFAKTQHASEB4efvz4cdhYvny5IT3/3wUkQCQSEdPH29u7Y8eOsPHw4cNevXqBs4AgHEZYH3hHR0cPHToUnPCEeygUCn5IgJpu3br5+vrGxsaCvykgIKBmzZoE4R5CsQKkUinU/xKJ5NixYw4ODoR78KAhkJFSpUq5ublBP+uOHTtWrFhBEO4hCAl49+5dvXr1wGXl6upKuApvGgIZgd+1evVqtsvwxIkT0EAgCGcQhAQEBgbevHkTuq8Jh+FfQ0ALHx8f+Fu5cuW1a9ey/kKEC/BZAqDyh+YobDRs2JBwHplMxm8JYClUqNDff//t7u4O21OnTsWvD40OnyVg3759kNuIiQBWAP98AZnBumPatGmzZs0a2IiLiyOIkeBhnvv48eP69ethY+LEiSY0Uo3HvoDMqFWr1pIlS2DjwYMHf/zxB/QdEMTg8E0CoP9p4MCBbL+0aSFACVBTv379Zs2a3bhxg6gUnCAGhD/jAqAI+fv7V6pUCXzOxAQRsgQAjRs3Zjf8/Pysra1nzZpFEIPAEyvgy5cvtWvX9vLyMt3mtKB8AVmwePFidhBRSEhIZGQkQfQMH/JcYmIiWI+3b992cXEhJovArQBNWrRhDCWwAAAQAElEQVRoAX9tbW379Olz4cIFgugT05YAKPmQXcRicZkyZYiJgxKghbOz86lTp/Llywfbx44di4+PJ4geyNQXAHYp4TyXL1/esWMHSMCP3S2nDG+BNAQYFdmPX65cOXgybm5uPXr0gHdtY2OjWj3BhOHaW85UAqKioghXgTyRkJAAHX6NGjUiubhVtobhCAKxAlJSUn6gPi9atOi///4L5yYnJyclJbEzl5ko0MDh1CeqJlntQAcyOI0Jv8CGwHeB+h+qUPiLIwjyEBPrFIRKABTU0dGR8A6UgGyiVn+wBEEO+FcZGBiTsQKgAQldRAab29/wYKdgTmGbA+wCJ8gPYxp5DmpIkID8+fPzuJ406bkDjQWYAGyt8PnzZ3YmeCSnZDfPvXnzRufqeg0bNmQn4SSqT8FXr15dr169KVOmaMbZsmXLoUOHoF9Hnc60adPq1KmjldTmzZv3799/8uRJzUCoG7t37w6RR40aBbuzZ8++efOm+ihUmwUKFChfvvyQIUNYgzCz+wTWrVvn7e1NuAovpwzJJk+ePDl+/PirV6++fPkCQg9dvJ07d/by8iKqxR2nTp26dOlS6BrQPGXBggXv3r3bsGEDu+vi4gKnnz9//unTp6Ghoa6urhUrVuzYsSP7SSKLTCY7ffo0JMh+qgwuRsirzZs3Z7sYIItu3Lgx473Z29ur10rI4j6JanzK0aNH79y5ExQUZGFhUbhw4bp167Zr147jrzVn1U6fPn20VpjVbJZfvHjRw8Pj1q1b0EjLK58tmHmUCnVIoUKFRo8ezW7DQ4c3evXqVXjrkEvU0TLeJwBiQTiMYBsCAQEBkyZNaty4MbxWeINxcXFbt26dOHHiokWL2CkGsgOUUqhpKleu3KJFC/AWRUREQF1y6dKlJUuWsLoPIdOnT4eiC7rQtGlT6JWAjLpixYoXL16MGTNGnc7MmTO1nAtqw/O79zl37lxQpQEDBoA6wO69e/fWr18fHBysmT4HyZkEFClSBMRV56GwsDAQYD8/P3jQUCbZAV4/DJj9MTExoC+gplr9wPCCNe+hVq1aFSpUgDrh+fPn6gFCWdwnZxFsQ+DUqVMlSpQYP368OgTe3YgRI+7evZtNCYBiDCYkFOxx48ZBblGo6NSpE5RYyJBgmUKcNWvWfPr06a+//lJX2s2aNQONWLhwYY0aNSAXsYFga2T2dWnW9wn5/+HDh3PmzKlevbr6qJWV1f/+9z+oqLjss8yzPHfmzBmon6HuhUcA9lguJQBEGrpPsxlZLfMmPUZQsA2BjD18UAjZZQuzCZifoJ6DBw9mawtaBRvCzl8M1QlYiz///LO6/LM0aNAA/kJDMjtXyfo+4RIZT+mhgnCbvMlzUGmfO3euSZMmRPXJ1+PHj3/4Aw+QTKJ6uNmvEsPDw4mqNUhMGcF2CkK1AdX4qlWroIn+Y2tbwYlQjDPW3hBYtWpV2IAMCXZBtWrVMp4LKpDNyibr+4R6COp8sDUuX74MzQ1iOuSNFQC2UFRUFFhWsA0P3dnZGYyCXr16kZyT026/R48egZ+vYMGCmo3/efPmaUUD2wSMNMJheD93YGZ069YNHHV79+7977//oBqH99hURfZtIugOyMzRyyYSHR1NVI498j3AUtAKGThwIBuY9X1C+YdGB7ge/vzzT9hl/ZFgAkDOJNwmZxKQsWixDwhMAF9fX3a8LTwdeC4QoicJCAwM1GxlwAuAhly/fv00rYaM7kDuTx8EDmphdmvBG4T3BXnmwYMH4HIPCQlZvnw5yDq02z09PUneYW5uTlTroII7KbMPDTK6A9Vl+Lv3CR4B8Dv4+/uD4xDshWvXrp09exbia7oPOEhuewTgAcEzBeeqRCLRav/DY9LqyMkCOJ3t/M94SGteTc0eAdBjsALA46pVwk3OHQidnfD04KcRoQIZqbUKorLswL+7adMmMNzYV58xY2i2m6ANCK6+LBIHs5SojAXoFYKWZkYfs5os3IFZ3yd7FG6pigqiGrwIPQKgAhC5VKlShKvkQY8A25MPz0KzoMKPB6dg9iUAFBrsNHjT0KBgXxhLnArNdr5mjwCoL5gh0J3LcaHNmrVr10Jnatu2bYnwgDcOrhwnJyfNuhfeL/Sos8u9s5khY+v6w4cP6lwBbmDIhFo5B3j79i3UQ/Bg2RIIHVWQIaHlr1n+d+/eDdeCPnySu/uEihBuUjMd6BeHzAkS8Pr1ay5LQB64A6HbA7pVoEu2ogb169cHPy1U4NlPhx0sBE4EzUCo5+GvTkcOUY1KgCYAPGXojySmCXRoQ/cHdCYTQQKO9CFDhkA51AqH/h22PEOtA1W3Vq6A1w3tQXX3W6tWrYhq6JfmN+NQJleuXHn06FHIhJBUw4YNIS+9evVK0wS4cuUK9O1nJ/N89z6hawDqIa2JD9ldEA7CYXLrDgRphGZPxuk6GzVqtGXLFhBItt9FC2hHgRGl3oX2Pwg5mMGQDryS9+/fQ7cCWHpQtkG527Vrl8WovjZt2kANAK0ysDvU7gCt9Fnc3Ny4NjoIVBI8qewsusIERBzcbDt27IDXDRUJUX1NfOLECejDmzFjBhtn2LBh0ESHAta+fXswFW/fvg1d9OA6admyJRsBuvomTJiwaNGiiRMndurUCer54OBg8NuBKT537lzWBTBq1CgwHCARiAB+K6lUyuYuuCg019X3A1ZDxj58uNZ37xOShb6AqVOnQmOZnSI9KCho586d0HDm+GKKuZWA06dPg6yyD0UT8IgWL178woULOiVAq9cXIrMhPXv2hBdw48YNeJRE1dHSv3//zp07k8wBRQfXALgDQKF79+6tM30WeDec6qSF3AZ6B0JJhA24jUGaL126BBUGNOmhPqhQocL8+fPBrmQjQO6aPn061OfgbAeDHOx/6H6GszQdwJDNoDEFlQGUOij/kIug3ELmUVvgEAJSCxEgd0GmhVodInTo0GHQoEGaXQ8615tnhydnfZ/58+dftmzZ8ePHQXrCwsKSk5OhSoM+Mq375CBUZj2x4DshxiAPBxd/FyNOGQImIjQUTXSy49wAZcO4U4CB4xlKrxGnHuLalCGc0yeTnhAmm4AxCa0bMGgJYnDYdgGihosjUnm/vBQ0YqE1SxBjAGYmSDBB0uCiBEDbjB0mzEvA37Fq1Sqt7ivEYIAj8MeGIfMVLjoqoC3AV50Gz+Xw4cNLlixJECMBfkGcnUkTjvoqefmS5s2bB73TP/30E0GMB/oCtMhUAoz7pKAhAL0v7JAPfrBhwwY3NzfohSLCRiQSGTdrvXjxArrrsvPJkJ7gWh9hpndjxGfEXj0pKen58+cZRxyYIocOHYqKipo8eTIRPGYqiPHYunVr3759vzsiWDhQ6BrRN1euXDly5MiyZcsIwgEePHjg6elp6rNL5CGcloCrV696e3ubtGCDIbNgwYLt27cTBOEknPa6Qc8ZO1LYRPn8+fPYsWOx/HOKbdu2vXz5kiBpcFoCypYtO3LkSNOahkmTli1bnj59miBcIiAg4MOHDwRJA30B+gLKP1Q47HzSCHd49OhRgQIFoHeGICpMoPt92rRpb968ISZFnz59/Pz8sPxzkIoVK2L518QEJKB58+bqRWNMgvHjxw8aNMikZzTnMfv37/f39ydIGiawdkVdFcRE+PPPP2vXrl2vXj2CcJJnz55ZWlr6+voSRIVp+AJiYmJiY2M9PDwIt/nnn39kMtnQoUMJwlWePn3q6OioudagwDGNofgODg7Dhw/nuCP36NGjcIdY/jkOdDNh+dfEZL7GmTNnTsbpALnDjRs3Lly4MH36dIJwG3bxX4KkYTLrWFaqVIlwlVevXq1evXrXrl0E4TzwslJSUtSzDyOmNC7g9u3bcXFx7MqF3CE6OrpLly7nzp0jiCnw8uVLcAfm7TpFJo2JDQ2qU6fO+fPnLSwsCGeoWbPmtWvXhLkuOMIDTGxmDmjIZVzj2Yi0bdv28OHDWP5NiP/9739XrlwhSBomJgEuLi6aQ+6MuwjXgAED5s+fz/2lYxFN3qggSBqm940AON5sbW0PHjwIPXB2dnYXL14kxuCPP/5o3rx5o0aNCGIKsAuBKlQQ1aRYsAGZn10RU8iYngV74sSJT58+sZMLmpmZBQQEVKhQgRiWJUuWVK5cGcu/CQHG2v379zVXvgUJ4MecVLnElCSgWbNmnz9/plWwIfBGDT/R6JYtW6ysrLp27UoQ0wFabaGhoZprZDk6Ovbq1YsIHlPyBbi5uWkVeBByTV03AP/9919QUNDIkSMJYlLUrl1ba4Vvb29vnM2ZmJYEbN++vWXLlloLvxpycbg7d+5A01HnypMI9+ndu7d6ykAbG5uePXsSxOR6BObOnfvrr7+6urqyu2ACGGw62sDAwKVLl65Zs4YgpkmVKlXKlSvHbnt5eaErh8X0VuwALYeuOA8PD2gFgAlgGAmIi4sbOHDgvn37CGLK9O3bF5qTYAJwapl546L3TsEnVxMeXvmSlCCXJivSrkmI+prqbYqB8swodCdC0QyjLO9EebOppzCM6tZpCFUeUEajRUShsRAZG5+hlP9LvRbRdelvVyHaNwAKqQpRMHKaEuk+i72r9IjNaTMLqpC3dYt+roTznPwnIiIkWSpRyCTKX0KJGEZOqTYoRq76bWmPLvVJa28on7Lmc1BuU8pHp46WlgLDNt3U7/HbWer2nHo3NRIbJ22bfUcUQ5i0EzTvTeN1p11FdaL6QvBX1SkITiXNo2x8BfPtLlJftNaFtLJT6k0pCPOtKk2927Q8qQ5UkPQ3pvGUNKOpHhKj8Tg0kyUZEZlRcimjMxwyoaOLWZcx3/ksUr8ScHLTx/dvEvMXsnQtYimTpJbO9HlFfQMMBW9FoT6QrqRB6WPkyuIOb0mzoKpkg1G/J0pMMzLNJ5r2ktRPnHy7NkVTqst9uxIlohl5eg1QXTHd/aS7e9XpVFocDcws6JgoxafgRIYo+s/yIhxm45RACwtxAW8rW0eRNEX581OfNiCiiEoClM+KUZVJWqnVjGpD+cwZVaFh87EyMvn2MNnHSxG23LA+G1WOZ1Lfo+rVq8qG8kGmvh2VnqjOTyv4bMGgUl86m6xGtmHfgOpaKr1Oe61qQWcvl6EAs+JOq/IOk3ZBQtTJpmYt+lsRVf4ITc1iL0cpU9QsxoRW/S6SrsjCXRGG0TyR3VAmqUgXLTVShkJJi2iFXEcNSYtphUxHuFhMSyVMaGBiQrS073R4u5m6zPQoAed3RwY+Sej2uxcRMJf3f/wQlPjrfG/CSTZOCSpdxcm3iSNBeEp8LDmy6m3vqT62DrpVQF++gNDXSa/9YwVe/oH6P7tZ2ogPrgon3GP34vf2juZY/vmNrT0p5uu0d2lwZhH0JQG3/ouydeLQ93xGpHRNp89hKYR7xHyWVm6Gcxzzn5qtncETF/VBt72vLwmIj5VD25IghBQraSuTygnHkCQRhYIp6I0rbQsDEQl88lXnEX0NxYjd7QAAEABJREFUEJYkySXJptfjqA8k4FLjnAIQuVyukOm3MwjhDnIJkSTr7m/DD931j9JpbLghjAiiA5GyT0HnEZQA/cMwFK7ahhgXOXT9GdYKgF5ZrPlSob6NLkEQI5HpuDt9SQBcD2s+BOEK0AgwcEMArYBvqIYvIogxYUjqWO8MoBWgfyiKIdx7FijQQgJyIE0ZVgKUVgBBVLAjxrkGCrSQUH0MoTsT6s0KYLCeSUX5KQg+CsSoqL6OMqwVQBhsCKSi+j6NIIgRoYBMRuphQ0DvqL4xRQ1AjAmjYOdJ0IHeGgKEQQ1gYT+XJwhiTKjMZtnUW0NAgSPi0qCwHYAYnUwnBtHXlzw/MC4gMPDNH5NGNW1ec+euzTNn/T5+wjBiPPoP/GXFXwtJnsBw0RvIe8PE6FnoB4Ai0LBx1ceP/Unek2nTnEPjAs5fOB3w+OHsmYt9fIoXKFBIKpUQXkBxcmQQ790T9eo1NuksFBT0dvLU0Xt2nSB5ApWpU5pDnwklJMRDya9dux5sFyjAn7U6GfxEwBg0btScmDIvXz0jeQiTaUtAXxIgEhOazkHOHzV64JMnj2ADDKFBA0e8evU8Pj7Ob+m6s2dPLlw8a8O6HcWKlYCjz54/GTGy3+xZi+vVzWoS+Ni42A0b/jp56qiDg2PVKjV+HTTKza0AhCcmJi5bscDf/15cXKyXp0/Llu07tP+ZPSU4OHDhopnvQoJ8fav26TVIM7WnTwO2btv44sVTB0enWjXr9u0z2MbGhggPyEMHD+0+c+bE+9B3nkW8q1atOaD/MJFItGfvNng+p/67xkb7+DGiW4828+b4/fRT/dlzJoEXCh7aEr+5ELNUybKzZi46cnQ/xLe3d2jerM3QIaMhAtR4AwZ1Xb3y343/rAoIeFjArWC3bn0r+VadPnNCaGhIqVJlR42cWKpkGaKqG48dP/Dg4d2IiHB4g61adWjfrgt73fYdG8OLu3LtAqRw9MgFP795bBZau275/gM7NX9Ivnz59+89BRtRUV/Wrlv25Omj5OTkatVqwekeHp5ZP4SDh/bs2r157JjJ0NDo0OGXUSMmyGSyTf+uvXX72qdPEeXK+XZs/0vNmnXYyLduX9+7d9uLl0+dnfOVK1dx8KBRLi75nr94OnxE37VrtpYuVZaN1qt3h9q16w8fNlZ9lc1b1m/b/g9RFQcI/7lLT51JkeyjmqFb5xF9+QLkMuWkNNmPv+qvTfAuvbx8Lp6/17NHf3V406atqlSu7rdsHlFlQdho0rhF1uUfXsmkyb99/hK5zG89ZJ1PkR8nTfkNAuEQbISHh86d47dvz0kwFP9auQjeB4RLpdI/Jo/Kn99ty78Hhvz6G+TpL19SF58LDXs/4ffhySnJq1dtnjt7aWDg67HjBrOpZRe+fCl46NCeHTv/7dK5B1inbdt2/u/kEXhQWZ8iFouhgME/KHLr126HjdFjf1Uo5CeOXZ45Y+G+/Ttu375OVMvDwt/Va5aCvF44d7dsuYp//7MKfDF//D7rzKkbFuYWK1ctZhNcs9bv7t2bo3/7Y+GfK6H8wxu8pUqBTeTEycPFipVcsniNtdW3JafatesCOYH9t2Decmtr63JlKxLVpCljxw/xf3R/7Jgp//6z18nRGUpmWHho1r/I3Nw8MTHh2LEDkyfNgdIOIXBvBw7u6tih666dx+vXazxz9u+Xr5yH8FevX0yeMrpSpWqQqX4b9fvbt68WLZ5Fskf/fkO7de0D9RYUByj/uUkqFUW6qYo10ZsvgM6zbD9+3LS+/TtDlZ6SkgKy/dfyf7KOD3r8/PmTrZsPFCniBbug65DV4MTAoDfgaIGX7e1dFMJBaG7fuQ7V0cIFf125euHTp4+QMmsswFP+uWtLNrVz506Zic2g8INBAbsTxk/v3rPtteuXGtRvQrIJNz8TyvlXXI8CHpQsWaZ58zaw3aZ1R8iRSYmJ3z1LIpGMHDEByic8QB/vYjK5DPI3hEMl7+jo9DbwtbrObNy4ReVK1WCjQb0m58+fhqJbprRy8R8Qa6irVTOOU9On/wklsGCBQmwKp08fu3P3Rs0aP6l+EAWWBVTLWjdQ2N0D/rHbs2b/kS+f68QJM2AbMkNISDCYCexFhw0dc/3G5YMHd8Hbz+LnwFXAZAAjhT0L8uSZ/53o0b1fu7adYbdVy/ZgzG7b/jdowZPH/paWlr16DqBpGvIVWDGQA8kPkfuklM5A2rDuwDx0OMNvBoNz49+r5DLZ1KnzbW1ts47/9u1rUHq2/AMlipeaNkVpRIC7EZ4jW/7TDpWGQNgIC3sPh9QOCDCxXF3d2O2nTx+BIcqWf6JyUhQqVBjcltmXAOUaJCIOfiOQY1kC+xPewuIlcypUqFSrVj33QoWzc5a7u4d6xScra2sX52/mq421Ddjq6l0PD6/UcNUrBr1IPcvSCsw0kBILCwu4bTBGQLvfv3/HHi1Y8NtSGSVLlMniTsCGB73YuGEXuyzl4yf+cGNsSSaqsu1bsQrIHMkG0KJhN6DFCjdWrWot9SFI5NTpYzGxMeXK+4JYTJ46Bpqi8LhAhkCzyA+R+6RSl4HQhf7GBeSlx7lTx25btm4Qi8QVylf6bmRwK1pYWGYMB9ve0tJKMwSyQlKSsh6LjY2xskq3Wqk6BcijL14+gyaZ5tGvUV9ItlEwciLng/sdmgDW1jZQVS5aPBss/AYNmkKjCdrVWZ+ltRh0FovBfzemQqGYNGU0qMGvg0aCy8bO1g5cSJoRwErPJG0CL3H9hhXQ36S2CODNgrJovVkwTEg2UF+IlTCt2yCqHAJ1D7RWrlw5D7oJ/ghoz/brOwRklOScPEgq8wH7erMCRDlzB2YNtDlB7OGFbfx75ZjRk7KODNkUCjZkF608BD685OQkzZCExIR8LsocDAYkqwVqwNpkN5xd8pUv78varmoc7IU49z48T7D/4R+4Th88uLNl20ZQW2hda0WTK/Q1WSo0icEpu3TJWigDbAiUwPz5vr9kG7iHp88Y371bX7a/iQVsPSsrq/np719E52zaaxeVAo4fN9U9TVlYXF2VLcoa1WvDP8g89+/fBk/qlKljDh08mzERaBx990IZkzpy+HwWeqoNbfBvBKDmy5E7MAsgw0GLfeVfm2RS6W9jBjVr2rpMmfJZxIeWElhNL189Zz2u0N6DXoBRIyaClQjhr9+8LF6sJBsTXAZeqnYBuKDhUGDgGx8fpfH55s2rz58j2ThFfYr/7+x/FStUVj9uuJ/ChYuQbMObLwWhL6BEidLQkgKvLfyLi4/77+RhovTDmUOTGFykYBrAbsi7IKIfYmKi4a+6zMOLgH/eXkWzPgucCPPmTYEuDC0dL1q0RFJSEpRVdYsm/EOYo0O2rAA1hd2LKJsnKscEG/L1axRcEQxMf//7KZIUKLdgKIEDBTq8x4wbHPHxA3g3IZq6yomPj1dntszQmVR8Qry9nT3JJorMpg7k/MrCUJnPWzC1SeOWUJ6hNobO3gULZ2TtkIfOKpDkjRtXXr128e69W+BYjvz00dPTu3r12tCMX7ZsPtiE4B2EjhyQgK4/94ZToEsGTLuly+aBEMD7mDNvMtgFbGpduvSEe1i91g8OQftzw8aV0H2VI2cMN78U/AFnDfhNZsyaeOPGFWjo3rp17eq1C6xrHRQZMv3pM8eJqkdw154tRD9ALyCozN5926FWB2VftXpJtao1oVBlfdbOXZvBdwMdeOD8f+h/j/0HhR9MCcgSS5fOhXsGcYGuyqHDeoN/keQEKOpgk4P/D5yL4BSAvgDoP2LHlUL3x6zZvx8/cSg6+it0Zh86vAcKMFQ24J+GJgy4t+GhQU5euHimna6SDNUMNF2vXbsEuU5nUrY2tiQv0JsvgMqbSSng/X2M+LDMbwO7C77lnr3bb9/xj5aiawK5ZOnitX8umjFj5kTYrVWr7p8L/mIrKOishgYh9P1AgffxKT53zlKQFQgHF+OC+StANdq0qw9+wcG//nbu/Ck2NRDaTf/s3bNn65BhvSDbgWtw4oTp0DYjJs4PjA6Erhnot5s6fRxsOzu7QIvg5y69YBvUGdzp8PT8ls0HOYAua6ij9LFWJTiGp06ZByZh+w6NQOWnTp77Jerz9BkT+vbvAh1AmZ0FpRqMFIimGbjp7z1g8f05f8Wx4wdB8Z89ewwls0mTlp06dSM5BHrvwKAA4YPGkY2NbdkyFcaPnwbhv/zcC0osPLFlyxdAfmvUsPnyZRvZfAj9GtCd2ahJNSjJQwaPhgop4+OqWaNO+XK+02dOgI5S6HHImFQOWgFKMv1WTV/Lim6cEuTkataif7acxvwmKUG+d0nQqOXFCJdIipdvmhbUdza37grRE9tmv63U0KF2Wx2jifRpBSAsOH0owmFMo1NQC2h3gUc0s6M7th9Rd+MjmYFTGGTGrt1bdu/eovOQp5fP6pX/ElMEXNKGnjVIxORhp6AW0IDfknnbj2vln5s9AjiRUWZ0aP9L82ZtdB5iW/KmSWZTB+qxU5DKq05BneTsGwmjgnMHmhbWKgjPMPzQIDpPhwYhCJIrqEzdc/qSAEXeDQ0ydbjZ6kZfgLAwwiTimMHS4GarG30BwkI5l6eBvxTEWgZBTAF9ejhRAxCEGzCZriemTwlABUiFm7MG4cLPQiJzV4A+ZxBGb2Aq3BwdiMs8ICr0ZgXggmIIYgrob+IwtDTTEHG1UYQvSDBQNCUy0z1CWF8SYGklomjTHU2Zl8gSiUjMuXkZrKxENAdnNET0g0hMWVrqLo/6ypr5ClvFRqUQhJBnt6PNLLk3NYuIiC3ogEuxBOE7kiSikDMVG+ieYkhfWbNlv/wpCfLI0JzMt89Tgp7Glq3uQLiHT1m7p3dyMA8qYqKc3BjqUiDTiVX1NWUIkBAj3zb/XbWmriWr580MRyaHXEL2rQguXcWubicXwkkuH/j89nHCz+M8CcJT/tsUThSKbhMynbxHjxIARH1gDqx6Bx1QFlailKTMJ5allL5D6EeklF1V6RqoVFoQkxoxXe8mRROtSRE1U0g9qnEOo+ECY4+y6asvpJlQamxGx13piJ8esPwVUkaSLPcpb9+8z3em2TYuh9d9+BiYaGYlEomJJDmrzJDxaZP0z0E7gvbb0ppLjlFN3q/xGHVONpcWqBFT8zWm5ZAsXgetnL1CFZPRHiSblvF0n0dD2VFHZJhsuE91ZEit20v/GzO77bRsn/6iGZ8Pmz91JaL8rJmiU5Jkdk7mvSZ7kCzuWa8SwPLgbExIUGJyXKaNAkr1GRM8O82HnnoofUHVisDuaj4CzQgZj2aMqY6vlTIbMzUFWsdiTBlvVRMLK9oxn2XDXzha+Wfk/J7IuC/S5OSs5v9W/2TNjE7TjEJBaUVg0cqa2rvsm9V4tjqz8jeNTruoVjHTyiFZ3DZ7q4mJiVKp1MHBgU0c/mX2HkUiIpdn67dkcTNsyLdHl/7EdCqTIXNqZbyMF01VCl3SbGZO2TlYVL2svoYAAAk3SURBVG2cz9n9O8plCAlAEO6wd+/ekJCQiRMnEkQF9tshwkK93gHCgs8CERbQClCvcYgQlABEaKAVoAU+C0RYoARowfUFxRAkb0EJ0AKfBSIs0BegBUoAIizQCtACnwUiLFACtMBngQgLlAAt8FkgwgIlQAt8FoiwAAlAd6AmKAGIsEArQAt8FoiwQAnQAp8FIixQArTAZ4EIC6lUihKgCT4LRFigFaAFPgtEWKAEaIHPAhEWKAFa4LNAhAVKgBb4LBBhgV8KaoESgAgLtAK0wGeBCAuUAC3wWSDCwtraGhsCmqAEIMIiNjYW187QBCUAERZgAoBHkCBpoAQgwgIcAeAOIEgaKAGIsEAJ0AIlABEWKAFaoAQgwgIlQAuUAERYoARogRKACAuUAC1QAhBhgRKgBUoAIixQArRACUCEBUqAFigBiLBACdACJQARFigBWqAEIMICJUALlABEWKAEaIESgAgLlAAtUAIQYYESoAWF0ycgQqBLly6Q1eVyeXR0tEgksrKygm2Qg+PHjxNhg1YAIgigtL9580a9GxMTAxJQrVo1InhogiACAKwAGxsbzRAXF5cePXoQwYMSgAgCkABPT0/NEHd39wYNGhDBgxKACIXu3buDC4DdBouga9euBEEJQIRDy5Ytvb292W0wAVq1akUQlABEUPTt29fBwcHCwqJjx44EUYGdgggX+RohDbgWExmekhQHnnuFNOVbLqVowigIpcy5lHKXIsosDJuMskZT/ldBvoUT7ZgJCQkyeYqDvZPqnLQTVUdhg70MG1MZQpTnMqlRldA0USi+3aeFJU3RlLkV7exmUaqKvUcpC2JqoAQg3OLo+g8R75JkUoYW0SIzmhaJaJqWy9nBPMrCmK7Mq/aVeVi1S6WVWtWB9BE0RYFWbmlnfAoKA2HUO4RRJaZdQFgBUiM2EzMKRi6VK//JFHCGU0GLln0KOrqKiImAEoBwhd1L3kdFSMytxPYFbN2KOhITJCo04XPIV2mizNpO3H+WJzEFUAIQ4/P8ZsLFQxFiC3HRmoVFJlN9ZsXbOxHJMUklqto37eFKuA1KAGJkTmz6+P5FgnvZ/PZu1oRPyMnzq+/snMS9JhUhHAZ7BBBj4n85LuRlYulGnnwr/4CIlG7gmRhPjm/8QDgMWgGI0VB6/oJSSjbwILzmzc0wMxHTdyZHXQNoBSDG4d7Z6LC3Sbwv/0CxWu7JKczhNeGEk6AEIMbh9ukvxasVJsKgZF2P8MCkwIBEwj1QAhAjsGVOiKWdhZkdL7z/2cPZ3eHMDi46BVACEEPzIUgS91VStEZBIiQKlnZiGOrS/i+EY6AEIIbm3J4IGwdLwlUOHl+8ZFV3ogccCtg9vxdNOAZKAGJoYj5JCpZ0IcLDvYyzXMaEvU4hXAIlADEod/8XTYspK0dzIkjMLMR3znCrLYBzByIGJehJvMhCj7nu7oMTN+8e/vDxTUG3Yr7lm9St1Y39dmj73imEUJUrtth7aE5KSqKnR/nWzUd6epSDQ7C788CMN4H34JRa1ToRfWJlZ/ElIplwCbQCEIMS91VqZaMvE+DBozN7D88tXKjklHGHWzYdduXGnqMnl7OHaFr87v3j+/6nRg/dsmDGZbGZ+Z5Dc9hD+47M//zl/ZB+q/t2XxTxKfDFq+tEb9jns5ZJuTUYDyUAMShSCWOhNwm4c/+oj2elTm1/t7N1Lu5TtXnjwddv74+Lj2KPQm3fteM0F2d3kUhcuULzyM/vICQmNvLRk3MN6/QGi8DezqVN85FmYj26Ku1crMEdQLgESgBiUBiGiMR6yXUKhSIoJKBE8RrqEFABhlEEBfuzu675vSwsUr9EsLS0g7+JSbFRX8Ngw83VW32Wh3tpojdEVjTXBuSjLwAxKFAm5ZSC6AGZTCKXS0+fWw//NMPjElKtAIrSIT0JiTHw18L820dK5uZWREigBCAGhRbRjH6W8zI3t4SSXMW3VYWyjTTDwfLP4iwbawf4K5F+c9ElpyQQvSFPkhOOgRKAGBQzc1oSr6+O8UIFSyQlxxXzqcLuymTSL1/DHB3csjjFybEQ/A0OCWDtfzjl9ds7NjZORD/EfE6kOdb4Rl8AYlDsnMTJCRKiH1o1Hfbk+eXb948p/QLv/Hfsm7ph8whoIGRxiqODq1eRimcubPwU+U4qTdm5fzo7baieiP+SbG7OrS8jUAIQg+JdxkaarC9j2NvTd+ywbeD/m7WoxYYto5KS4/v3XGJm9p1Zfbt3nlmkcNkV6/pMndfQ2sq+euV2RG+TaCTHJjsX4tYswzhlCGJo1ox/61OlkJWTEAcIPjkb1Gm4R6FiHFIBtAIQQ+OQTxz28jMRHuFPvojEFKfKP0F3IGJ4mvQoeOCvkCwiQGP++Om/dB6C5npmhn23TjPKla5P8ghwJWzaMV7nIXAuiERmlC6XQac2v1eu2JxkQnRkfNlqnJscHRsCiBHYPCtYwdBFa+rurktOTkhMitF5KCEx1sbaXuchWxtn6BckeUfUV91TfSUnx1ta2uo8ZGPtqB59pEX4i+jYiJihi3wIx0AJQIzDmglvi1fzMLcXysRBT88Ftxno7lmGcxMloC8AMQ41mrm8ufeeCIOX10ILFbXiYPknKAGIsajazNG9mM3LyyGE77y5EWppSToOL0Q4CTYEEGPy9Hr85aORZRpyer2d3PDqemghb8s2A90IV0ErADEmZX+y9Spj9ezCu5jwJMIvFFLy/NI7a2uKy+WfoBWAcIGX9xIv7I0QWYiLVi4osuJDtfT29oekuOSyNRwa/pKfcBuUAIQr7F0W+jksRWwhcixo51bMJBcX/xIc/zU8JjlRYqNcXNyLmAIoAQi3OLIuPCI4WS5jRGJaZEbTYpqiaIVC87MCihDm238hA3//wx7lQB4dWT0tJc2IyqDUQEYVI/0JFKN5ikhEEwUllcsZqVwmlVM0la+QRct+7nZOevzWKG9BCUC4SHwU8/DSl0/vU5IS5XKZQpKkkUuVhVBZwChaWSIVTLoyCYFKTSDpvvRRxVSGqANVikBEYiJPP3mBKiajUKgKsKZAqLbZOUcYjRlPzC0okTltYUm7FLQoXcO+oDe3Bv9mB5QABBE0+I0AgggalAAEETQoAQgiaFACEETQoAQgiKBBCUAQQfN/AAAA//+NegvBAAAABklEQVQDAE0XsAu1YilLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_graph = StateGraph(State, ExecutionDeps)\n",
    "\n",
    "code_graph.add_node(\"write_code\", write_code_for_task)\n",
    "code_graph.add_node(\"move_data\", move_data_to_execution_folder)\n",
    "code_graph.add_node(\"execute_code\", execute_code)\n",
    "code_graph.add_node(\"fix_code\", code_fix)\n",
    "code_graph.add_node(\"summarize_results\", summarize_results)\n",
    "\n",
    "code_graph.add_edge(START, \"write_code\")\n",
    "\n",
    "\n",
    "code_graph.add_edge(\"write_code\", \"move_data\")\n",
    "code_graph.add_edge(\"move_data\", \"execute_code\")\n",
    "code_graph.add_conditional_edges(\n",
    "    \"execute_code\",\n",
    "    check_execution_success,\n",
    "    {\"SUCCESS\": \"summarize_results\", \"FAILURE\": \"fix_code\"}\n",
    ")\n",
    "code_graph.add_edge(\"fix_code\", \"execute_code\")\n",
    "\n",
    "code_graph.add_edge(\"summarize_results\", END)\n",
    "\n",
    "\n",
    "code_workflow = code_graph.compile()\n",
    "\n",
    "display(Image(code_workflow.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a2a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-18 23:59:53.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:53.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mEXECUTING: eda\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:53.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:53.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1müîß Executing code in: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/execution\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1m‚úÖ Execution successful (1.45s)\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m   Generated 1 files\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1müì¶ Saving outputs...\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_code\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1müíæ Saved code: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/20251118_235955_code_with_data.py\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_console_output\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1müìÑ Saved console output: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/console_output_20251118_235955.txt\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_json\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1müìä Saved JSON: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/execution_info.json\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1müìÅ Copying 1 generated files...\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/plots/numerical_distribution_plots.png\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/plots/dataset_analysis_visualizations.png\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/data/data.csv\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/eda/dataset_summary.txt\u001b[0m\n",
      "\u001b[32m2025-11-18 23:59:55.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m‚úÖ All outputs saved for eda\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = await code_workflow.ainvoke(\n",
    "    {\n",
    "        \"user_query\": \"Perform a summary analysis of the dataset.\",\n",
    "        \"input_data_path\": \"data.csv\",\n",
    "        \"stage_name\": \"eda\"\n",
    "    },\n",
    "    context={\n",
    "        'output_manager': output_mgr,\n",
    "        'executor': executor\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648153b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                            <span style=\"font-weight: bold; text-decoration: underline\">Summary of Dataset Analysis</span>                                            \n",
       "\n",
       "The code successfully loaded and analyzed a dataset containing 1500 samples and 6 features (feature_0 to feature_4)\n",
       "along with a target variable. Here's a detailed breakdown of the findings:                                         \n",
       "\n",
       "<span style=\"font-weight: bold\">1. Data Loading and Shape:</span>                                                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The dataset was loaded without errors.                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The dataset's shape is (1500, 6), indicating 1500 rows (samples) and 6 columns (features + target).             \n",
       "\n",
       "<span style=\"font-weight: bold\">2. Data Inspection (First 5 Rows):</span>                                                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The first 5 rows were displayed, providing a glimpse of the data distribution. The features and target variable \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>appear to be continuous numerical values.                                                                       \n",
       "\n",
       "<span style=\"font-weight: bold\">3. Data Information:</span>                                                                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The dataset is a Pandas DataFrame.                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>All 6 columns are of type <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">float64</span>.                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The DataFrame uses a <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">RangeIndex</span> from 0 to 1499.                                                                 \n",
       "\n",
       "<span style=\"font-weight: bold\">4. Descriptive Statistics:</span>                                                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Mean:</span> The mean values for each feature and the target variable are relatively close to zero, suggesting a       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>centered distribution.                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Standard Deviation:</span> The standard deviations range from approximately 1.22 to 2.45 for the features and 1.30 for \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>the target, indicating the spread or dispersion of the data.  Feature_1 has the highest standard deviation,     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>implying greater variability.                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Min/Max:</span> The minimum and maximum values provide the range of each feature and the target. The ranges vary       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>considerably between features.                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Quantiles (25%, 50%, 75%):</span> These values show the distribution of the data. The median (50th percentile) is a    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>good indicator of the central tendency, and the interquartile range (IQR = 75% - 25%) provides information about\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>the spread of the middle 50% of the data.                                                                       \n",
       "\n",
       "<span style=\"font-weight: bold\">5. Missing Values:</span>                                                                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>There are no missing values in any of the columns, indicating a complete dataset.                               \n",
       "\n",
       "<span style=\"font-weight: bold\">6. Duplicate Rows:</span>                                                                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The analysis confirms that there are no duplicate rows in the dataset.                                          \n",
       "\n",
       "<span style=\"font-weight: bold\">7. Data Types:</span>                                                                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>All columns are correctly identified as <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">float64</span>.                                                                \n",
       "\n",
       "<span style=\"font-weight: bold\">8. Additional Outputs:</span>                                                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The code generated a visualization (saved as 'dataset_analysis_visualizations.png') and a summary report (saved \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>as 'dataset_summary.txt').  While the contents of these files aren't provided, they likely contain visual       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>representations of the data distribution (histograms, box plots, scatter plots) and a more detailed textual     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>summary of the analysis.                                                                                        \n",
       "\n",
       "<span style=\"font-weight: bold\">Overall:</span>                                                                                                           \n",
       "\n",
       "The dataset appears to be well-structured and clean, with no missing or duplicate values. The features and target  \n",
       "variable are continuous numerical values. The descriptive statistics provide a good initial understanding of the   \n",
       "data distribution and potential relationships between variables. The generated visualizations and summary report   \n",
       "would provide further insights into the dataset's characteristics.                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                            \u001b[1;4mSummary of Dataset Analysis\u001b[0m                                            \n",
       "\n",
       "The code successfully loaded and analyzed a dataset containing 1500 samples and 6 features (feature_0 to feature_4)\n",
       "along with a target variable. Here's a detailed breakdown of the findings:                                         \n",
       "\n",
       "\u001b[1m1. Data Loading and Shape:\u001b[0m                                                                                         \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe dataset was loaded without errors.                                                                          \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe dataset's shape is (1500, 6), indicating 1500 rows (samples) and 6 columns (features + target).             \n",
       "\n",
       "\u001b[1m2. Data Inspection (First 5 Rows):\u001b[0m                                                                                 \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe first 5 rows were displayed, providing a glimpse of the data distribution. The features and target variable \n",
       "\u001b[1;33m   \u001b[0mappear to be continuous numerical values.                                                                       \n",
       "\n",
       "\u001b[1m3. Data Information:\u001b[0m                                                                                               \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe dataset is a Pandas DataFrame.                                                                              \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mAll 6 columns are of type \u001b[1;36;40mfloat64\u001b[0m.                                                                              \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe DataFrame uses a \u001b[1;36;40mRangeIndex\u001b[0m from 0 to 1499.                                                                 \n",
       "\n",
       "\u001b[1m4. Descriptive Statistics:\u001b[0m                                                                                         \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mMean:\u001b[0m The mean values for each feature and the target variable are relatively close to zero, suggesting a       \n",
       "\u001b[1;33m   \u001b[0mcentered distribution.                                                                                          \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mStandard Deviation:\u001b[0m The standard deviations range from approximately 1.22 to 2.45 for the features and 1.30 for \n",
       "\u001b[1;33m   \u001b[0mthe target, indicating the spread or dispersion of the data.  Feature_1 has the highest standard deviation,     \n",
       "\u001b[1;33m   \u001b[0mimplying greater variability.                                                                                   \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mMin/Max:\u001b[0m The minimum and maximum values provide the range of each feature and the target. The ranges vary       \n",
       "\u001b[1;33m   \u001b[0mconsiderably between features.                                                                                  \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mQuantiles (25%, 50%, 75%):\u001b[0m These values show the distribution of the data. The median (50th percentile) is a    \n",
       "\u001b[1;33m   \u001b[0mgood indicator of the central tendency, and the interquartile range (IQR = 75% - 25%) provides information about\n",
       "\u001b[1;33m   \u001b[0mthe spread of the middle 50% of the data.                                                                       \n",
       "\n",
       "\u001b[1m5. Missing Values:\u001b[0m                                                                                                 \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThere are no missing values in any of the columns, indicating a complete dataset.                               \n",
       "\n",
       "\u001b[1m6. Duplicate Rows:\u001b[0m                                                                                                 \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe analysis confirms that there are no duplicate rows in the dataset.                                          \n",
       "\n",
       "\u001b[1m7. Data Types:\u001b[0m                                                                                                     \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mAll columns are correctly identified as \u001b[1;36;40mfloat64\u001b[0m.                                                                \n",
       "\n",
       "\u001b[1m8. Additional Outputs:\u001b[0m                                                                                             \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe code generated a visualization (saved as 'dataset_analysis_visualizations.png') and a summary report (saved \n",
       "\u001b[1;33m   \u001b[0mas 'dataset_summary.txt').  While the contents of these files aren't provided, they likely contain visual       \n",
       "\u001b[1;33m   \u001b[0mrepresentations of the data distribution (histograms, box plots, scatter plots) and a more detailed textual     \n",
       "\u001b[1;33m   \u001b[0msummary of the analysis.                                                                                        \n",
       "\n",
       "\u001b[1mOverall:\u001b[0m                                                                                                           \n",
       "\n",
       "The dataset appears to be well-structured and clean, with no missing or duplicate values. The features and target  \n",
       "variable are continuous numerical values. The descriptive statistics provide a good initial understanding of the   \n",
       "data distribution and potential relationships between variables. The generated visualizations and summary report   \n",
       "would provide further insights into the dataset's characteristics.                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "console.print(Markdown(result[\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-19 00:00:45.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:45.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mEXECUTING: regression\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:45.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:45.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1müîß Executing code in: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/execution\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1m‚úÖ Execution successful (1.37s)\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m   Generated 1 files\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1müì¶ Saving outputs...\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_code\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1müíæ Saved code: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/20251119_000047_code_with_data.py\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_console_output\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1müìÑ Saved console output: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/console_output_20251119_000047.txt\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_json\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1müìä Saved JSON: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/execution_info.json\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1müìÅ Copying 1 generated files...\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/plots/p_values.png\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/plots/feature_pvalues.png\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/plots/feature_coefficients.png\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/plots/linear_regression_coefficients.png\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/plots/vif_plot.png\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/data/data.csv\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/regression/data/feature_importance_analysis.csv\u001b[0m\n",
      "\u001b[32m2025-11-19 00:00:47.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m‚úÖ All outputs saved for regression\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = await code_workflow.ainvoke(\n",
    "    {\n",
    "        \"user_query\": f\"Perform a linear regression on the dataset provided and identify important features for predicting the target, try using statsmodels. Here is a summary of the data {result['summary']}\",\n",
    "        \"input_data_path\": \"data.csv\",\n",
    "        \"stage_name\": \"regression\"\n",
    "    },\n",
    "    context={\n",
    "        'output_manager': output_mgr,\n",
    "        'executor': executor\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdd7248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                <span style=\"font-weight: bold; text-decoration: underline\">Summary of Code Execution and Statistical Findings</span>                                 \n",
       "\n",
       "The code executed successfully, performing data loading, cleaning, exploratory data analysis (EDA), and linear     \n",
       "regression modeling. Here's a detailed summary of the results:                                                     \n",
       "\n",
       "<span style=\"font-weight: bold\">1. Data Loading and Cleaning:</span>                                                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>A dataset with 1500 samples and 6 features (feature_0 to feature_4) along with a target variable was loaded     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>successfully.                                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The dataset was checked for missing values and duplicates.  No missing values or duplicate rows were found,     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>indicating a clean dataset ready for analysis.                                                                  \n",
       "\n",
       "<span style=\"font-weight: bold\">2. Exploratory Data Analysis (EDA):</span>                                                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Descriptive statistics (mean, standard deviation, min, max, quartiles) were calculated for each feature and the \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>target variable. This provides a basic understanding of the data distribution.                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The mean of the target variable is approximately 0.0046, suggesting the target is centered around zero.         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Feature_0 has the largest standard deviation (1.217), indicating the greatest variability.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The range of values for each feature is substantial, suggesting a wide spread of data.                          \n",
       "\n",
       "<span style=\"font-weight: bold\">3. Linear Regression Modeling:</span>                                                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>A linear regression model was trained to predict the target variable using all 6 features.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Model Performance:</span> The R-squared value is 0.422, meaning that approximately 42.2% of the variance in the target \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>variable is explained by the model. The adjusted R-squared is 0.420, which accounts for the number of predictors\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>in the model.                                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Statistical Significance:</span> The F-statistic is 217.7 with a very small p-value (1.14e-174), indicating that the   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>model as a whole is statistically significant.                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Coefficient Analysis:</span> The coefficients from the linear regression model represent the change in the target      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>variable for a one-unit change in the corresponding feature, holding all other features constant.               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span><span style=\"font-weight: bold\">feature_0</span> has a positive and statistically significant coefficient (0.4845, p &lt; 0.001). This suggests that an\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>increase in feature_0 is associated with an increase in the target variable.                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span><span style=\"font-weight: bold\">feature_1</span> has a negative and statistically significant coefficient (-0.2151, p &lt; 0.001). This suggests that  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>an increase in feature_1 is associated with a decrease in the target variable.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span><span style=\"font-weight: bold\">feature_2, feature_3, and feature_4</span> are not statistically significant (p &gt; 0.05), indicating that they do not\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>have a significant impact on the target variable in this model.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span>The intercept (const) is not statistically significant (p = 0.763).                                          \n",
       "\n",
       "<span style=\"font-weight: bold\">4. Feature Importance:</span>                                                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Based on the p-values from the linear regression model, <span style=\"font-weight: bold\">feature_0 and feature_1</span> are identified as the most      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>important features, as they are the only ones with statistically significant coefficients.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The absolute values of the coefficients can also be used as a measure of feature importance.  Feature_0 has the \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>largest absolute coefficient (0.4845), indicating it has the strongest influence on the target variable.        \n",
       "\n",
       "<span style=\"font-weight: bold\">5. Output and Files:</span>                                                                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>The analysis results, including feature importance and coefficients, were saved to a CSV file named             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_importance_analysis.csv</span>.                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>A visualization of the feature coefficients was saved as a PNG image named <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_coefficients.png</span>.            \n",
       "\n",
       "<span style=\"font-weight: bold\">In conclusion:</span>                                                                                                     \n",
       "\n",
       "The linear regression model provides a moderate explanation of the variance in the target variable. Feature_0 and  \n",
       "Feature_1 are the most important predictors, with Feature_0 having the strongest positive influence and Feature_1  \n",
       "having a negative influence. The other features do not appear to have a statistically significant impact on the    \n",
       "target variable in this model.  Further analysis could explore interactions between features or consider different \n",
       "modeling techniques to potentially improve the model's performance.                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                \u001b[1;4mSummary of Code Execution and Statistical Findings\u001b[0m                                 \n",
       "\n",
       "The code executed successfully, performing data loading, cleaning, exploratory data analysis (EDA), and linear     \n",
       "regression modeling. Here's a detailed summary of the results:                                                     \n",
       "\n",
       "\u001b[1m1. Data Loading and Cleaning:\u001b[0m                                                                                      \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mA dataset with 1500 samples and 6 features (feature_0 to feature_4) along with a target variable was loaded     \n",
       "\u001b[1;33m   \u001b[0msuccessfully.                                                                                                   \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe dataset was checked for missing values and duplicates.  No missing values or duplicate rows were found,     \n",
       "\u001b[1;33m   \u001b[0mindicating a clean dataset ready for analysis.                                                                  \n",
       "\n",
       "\u001b[1m2. Exploratory Data Analysis (EDA):\u001b[0m                                                                                \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mDescriptive statistics (mean, standard deviation, min, max, quartiles) were calculated for each feature and the \n",
       "\u001b[1;33m   \u001b[0mtarget variable. This provides a basic understanding of the data distribution.                                  \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe mean of the target variable is approximately 0.0046, suggesting the target is centered around zero.         \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mFeature_0 has the largest standard deviation (1.217), indicating the greatest variability.                      \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe range of values for each feature is substantial, suggesting a wide spread of data.                          \n",
       "\n",
       "\u001b[1m3. Linear Regression Modeling:\u001b[0m                                                                                     \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mA linear regression model was trained to predict the target variable using all 6 features.                      \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mModel Performance:\u001b[0m The R-squared value is 0.422, meaning that approximately 42.2% of the variance in the target \n",
       "\u001b[1;33m   \u001b[0mvariable is explained by the model. The adjusted R-squared is 0.420, which accounts for the number of predictors\n",
       "\u001b[1;33m   \u001b[0min the model.                                                                                                   \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mStatistical Significance:\u001b[0m The F-statistic is 217.7 with a very small p-value (1.14e-174), indicating that the   \n",
       "\u001b[1;33m   \u001b[0mmodel as a whole is statistically significant.                                                                  \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mCoefficient Analysis:\u001b[0m The coefficients from the linear regression model represent the change in the target      \n",
       "\u001b[1;33m   \u001b[0mvariable for a one-unit change in the corresponding feature, holding all other features constant.               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mfeature_0\u001b[0m has a positive and statistically significant coefficient (0.4845, p < 0.001). This suggests that an\n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mincrease in feature_0 is associated with an increase in the target variable.                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mfeature_1\u001b[0m has a negative and statistically significant coefficient (-0.2151, p < 0.001). This suggests that  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0man increase in feature_1 is associated with a decrease in the target variable.                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mfeature_2, feature_3, and feature_4\u001b[0m are not statistically significant (p > 0.05), indicating that they do not\n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0mhave a significant impact on the target variable in this model.                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0mThe intercept (const) is not statistically significant (p = 0.763).                                          \n",
       "\n",
       "\u001b[1m4. Feature Importance:\u001b[0m                                                                                             \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mBased on the p-values from the linear regression model, \u001b[1mfeature_0 and feature_1\u001b[0m are identified as the most      \n",
       "\u001b[1;33m   \u001b[0mimportant features, as they are the only ones with statistically significant coefficients.                      \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe absolute values of the coefficients can also be used as a measure of feature importance.  Feature_0 has the \n",
       "\u001b[1;33m   \u001b[0mlargest absolute coefficient (0.4845), indicating it has the strongest influence on the target variable.        \n",
       "\n",
       "\u001b[1m5. Output and Files:\u001b[0m                                                                                               \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mThe analysis results, including feature importance and coefficients, were saved to a CSV file named             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;36;40mfeature_importance_analysis.csv\u001b[0m.                                                                                \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0mA visualization of the feature coefficients was saved as a PNG image named \u001b[1;36;40mfeature_coefficients.png\u001b[0m.            \n",
       "\n",
       "\u001b[1mIn conclusion:\u001b[0m                                                                                                     \n",
       "\n",
       "The linear regression model provides a moderate explanation of the variance in the target variable. Feature_0 and  \n",
       "Feature_1 are the most important predictors, with Feature_0 having the strongest positive influence and Feature_1  \n",
       "having a negative influence. The other features do not appear to have a statistically significant impact on the    \n",
       "target variable in this model.  Further analysis could explore interactions between features or consider different \n",
       "modeling techniques to potentially improve the model's performance.                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(result[\"summary\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb021ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-19 00:01:55.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mEXECUTING: what_if_analysis\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1müîß Executing code in: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/execution\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1m‚úÖ Execution successful (0.53s)\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m   Generated 1 files\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1müì¶ Saving outputs...\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_code\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1müíæ Saved code: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/20251119_000155_code_with_data.py\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_console_output\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1müìÑ Saved console output: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/console_output_20251119_000155.txt\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_json\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1müìä Saved JSON: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/execution_info.json\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1müìÅ Copying 1 generated files...\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/plots/feature_0_target_relationship.png\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/data/expected_change_summary.csv\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/what_if_analysis/data/data.csv\u001b[0m\n",
      "\u001b[32m2025-11-19 00:01:55.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m‚úÖ All outputs saved for what_if_analysis\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = await code_workflow.ainvoke(\n",
    "    {\n",
    "        \"user_query\": f\"What would the expected change in the target be if the value of feature 5 changed from 1 to 2 given the previous linear model results. Here is a summary of previous analysis{result['summary']}. {result['code_output'].stdout}\",\n",
    "        \"input_data_path\": \"data.csv\",\n",
    "        \"stage_name\": \"what_if_analysis\"\n",
    "    },\n",
    "    context={\n",
    "        'output_manager': output_mgr,\n",
    "        'executor': executor\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d8efcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                         <span style=\"font-weight: bold; text-decoration: underline\">Summary of Code Execution Results</span>                                         \n",
       "\n",
       "The code execution successfully calculated the expected change in the target variable when a specific feature      \n",
       "(feature_0) increases from 1 to 2. The result indicates that increasing feature_0 from 1 to 2 is predicted to      \n",
       "<span style=\"font-style: italic\">increase</span> the target variable by <span style=\"font-weight: bold\">0.4845 units</span>.                                                                      \n",
       "\n",
       "<span style=\"font-weight: bold\">Justification:</span>                                                                                                     \n",
       "\n",
       "The output explicitly states: \"Expected change in target when feature_0 changes from 1 to 2: 0.4845. This means the\n",
       "target variable would increase by 0.4845 units.\"  This is a clear and direct result of the code's operation.       \n",
       "\n",
       "<span style=\"font-weight: bold\">Statistical Findings:</span>                                                                                              \n",
       "\n",
       "While the output provides a point estimate of the change, it doesn't provide any information about the <span style=\"font-style: italic\">statistical </span>\n",
       "<span style=\"font-style: italic\">significance</span> or <span style=\"font-style: italic\">confidence interval</span> around this estimate.  To fully interpret this result, we would ideally need   \n",
       "additional information such as:                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Standard Error:</span>  This would tell us the precision of the estimate.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">P-value:</span> This would indicate the probability of observing such a change if there was actually no effect.        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Confidence Interval:</span> This would provide a range within which we can be reasonably confident the true change     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>lies.                                                                                                           \n",
       "\n",
       "Without these, we can only state that the model <span style=\"font-style: italic\">predicts</span> an increase of 0.4845, but we cannot assess the           \n",
       "reliability of this prediction.                                                                                    \n",
       "\n",
       "<span style=\"font-weight: bold\">Absence of Errors:</span>                                                                                                 \n",
       "\n",
       "The fact that there were no errors during execution is positive. It indicates the code ran as expected and produced\n",
       "a valid result, even if further statistical analysis is needed to fully understand its implications.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                         \u001b[1;4mSummary of Code Execution Results\u001b[0m                                         \n",
       "\n",
       "The code execution successfully calculated the expected change in the target variable when a specific feature      \n",
       "(feature_0) increases from 1 to 2. The result indicates that increasing feature_0 from 1 to 2 is predicted to      \n",
       "\u001b[3mincrease\u001b[0m the target variable by \u001b[1m0.4845 units\u001b[0m.                                                                      \n",
       "\n",
       "\u001b[1mJustification:\u001b[0m                                                                                                     \n",
       "\n",
       "The output explicitly states: \"Expected change in target when feature_0 changes from 1 to 2: 0.4845. This means the\n",
       "target variable would increase by 0.4845 units.\"  This is a clear and direct result of the code's operation.       \n",
       "\n",
       "\u001b[1mStatistical Findings:\u001b[0m                                                                                              \n",
       "\n",
       "While the output provides a point estimate of the change, it doesn't provide any information about the \u001b[3mstatistical \u001b[0m\n",
       "\u001b[3msignificance\u001b[0m or \u001b[3mconfidence interval\u001b[0m around this estimate.  To fully interpret this result, we would ideally need   \n",
       "additional information such as:                                                                                    \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mStandard Error:\u001b[0m  This would tell us the precision of the estimate.                                              \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mP-value:\u001b[0m This would indicate the probability of observing such a change if there was actually no effect.        \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mConfidence Interval:\u001b[0m This would provide a range within which we can be reasonably confident the true change     \n",
       "\u001b[1;33m   \u001b[0mlies.                                                                                                           \n",
       "\n",
       "Without these, we can only state that the model \u001b[3mpredicts\u001b[0m an increase of 0.4845, but we cannot assess the           \n",
       "reliability of this prediction.                                                                                    \n",
       "\n",
       "\u001b[1mAbsence of Errors:\u001b[0m                                                                                                 \n",
       "\n",
       "The fact that there were no errors during execution is positive. It indicates the code ran as expected and produced\n",
       "a valid result, even if further statistical analysis is needed to fully understand its implications.               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(result['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fa66ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-16 20:47:28.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:28.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mEXECUTING: sensitivity_analysis\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:28.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:28.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1müîß Executing code in: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/execution\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:29.509\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m162\u001b[0m - \u001b[31m\u001b[1m‚ùå Execution failed: Exit code: 1\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:29.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1müì¶ Saving outputs...\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:29.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_code\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1müíæ Saved code: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/code_with_data.py\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:29.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_console_output\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1müìÑ Saved console output: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/console_output.txt\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:29.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_json\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1müìä Saved JSON: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/execution_info.json\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:29.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m‚úÖ All outputs saved for sensitivity_analysis\n",
      "\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:37.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:37.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mEXECUTING: sensitivity_analysis\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:37.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:37.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1müîß Executing code in: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/execution\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1m‚úÖ Execution successful (0.98s)\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m   Generated 1 files\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1müì¶ Saving outputs...\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_code\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1müíæ Saved code: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/code_with_data.py\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_console_output\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1müìÑ Saved console output: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/console_output.txt\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_json\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1müìä Saved JSON: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/execution_info.json\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m319\u001b[0m - \u001b[1müìÅ Copying 1 generated files...\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/plots/sensitivity_analysis_plot.png\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36mcopy_generated_files\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1müì¶ Copied file: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/sensitivity_analysis/data/data.csv\u001b[0m\n",
      "\u001b[32m2025-11-16 20:47:38.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m‚úÖ All outputs saved for sensitivity_analysis\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = await code_workflow.ainvoke(\n",
    "    {\n",
    "        \"user_query\": f\"Can you perform a sensitivity analysis on the previous linear model results considering the impact of removing features 2 through 4? the data only contains features 0-4. Here is a summary of previous analysis{result['summary']}. {result['code_output'].stdout}\",\n",
    "        \"input_data_path\": \"data.csv\",\n",
    "        \"stage_name\": \"sensitivity_analysis\"\n",
    "    },\n",
    "    context={\n",
    "        'output_manager': output_mgr,\n",
    "        'executor': executor\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eafa0183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "               <span style=\"font-weight: bold; text-decoration: underline\">Summary of Code Execution Results: Feature Importance and Model Sensitivity Analysis</span>                \n",
       "\n",
       "The code execution performed a sensitivity analysis on the coefficient of <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> in a model. The goal was to    \n",
       "quantify how a small change in the coefficient impacts the predicted change in the target variable when <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span>  \n",
       "changes.                                                                                                           \n",
       "\n",
       "<span style=\"font-weight: bold\">Key Findings:</span>                                                                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Coefficient Change:</span> The original coefficient for <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> was 0.4845. After a reduction (presumably through    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>some model modification or regularization, though the specifics aren't provided), the coefficient became 0.4819.\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>This represents a decrease of 0.0026.                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Sensitivity:</span> The sensitivity analysis shows that a change of 0.0026 in the coefficient of <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> results in a\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>corresponding change of -0.0026 in the expected change in the target variable when <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> increases from 1 to\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>2.  This is a direct, linear relationship as expected given the simple model structure implied by focusing on a \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>single coefficient.                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Expected Change in Target:</span> The original model predicted a decrease of 0.4845 in the target variable when        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> changed from 1 to 2. The reduced model predicted a decrease of 0.4819. The difference between these   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>predictions (-0.0026) confirms the sensitivity calculation.                                                     \n",
       "\n",
       "<span style=\"font-weight: bold\">Justification:</span>                                                                                                     \n",
       "\n",
       "The output clearly shows the original and reduced coefficients for <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span>. The \"Sensitivity\" value (0.0026) is  \n",
       "calculated as the difference between the original and reduced coefficients.  The \"Expected change in target\" values\n",
       "are calculated by multiplying the original/reduced coefficients by the change in <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> (2-1 = 1).  The \"Change \n",
       "in expected change\" is simply the difference between the expected changes calculated using the original and reduced\n",
       "models, and it matches the sensitivity value.                                                                      \n",
       "\n",
       "<span style=\"font-weight: bold\">In conclusion,</span> the code successfully quantified the impact of a small change in the coefficient of <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">feature_0</span> on the\n",
       "model's predictions. The sensitivity analysis demonstrates a linear relationship, where a decrease of 0.0026 in the\n",
       "coefficient leads to a decrease of 0.0026 in the predicted change in the target variable.  The absence of errors   \n",
       "indicates the code executed without issues.                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "               \u001b[1;4mSummary of Code Execution Results: Feature Importance and Model Sensitivity Analysis\u001b[0m                \n",
       "\n",
       "The code execution performed a sensitivity analysis on the coefficient of \u001b[1;36;40mfeature_0\u001b[0m in a model. The goal was to    \n",
       "quantify how a small change in the coefficient impacts the predicted change in the target variable when \u001b[1;36;40mfeature_0\u001b[0m  \n",
       "changes.                                                                                                           \n",
       "\n",
       "\u001b[1mKey Findings:\u001b[0m                                                                                                      \n",
       "\n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mCoefficient Change:\u001b[0m The original coefficient for \u001b[1;36;40mfeature_0\u001b[0m was 0.4845. After a reduction (presumably through    \n",
       "\u001b[1;33m   \u001b[0msome model modification or regularization, though the specifics aren't provided), the coefficient became 0.4819.\n",
       "\u001b[1;33m   \u001b[0mThis represents a decrease of 0.0026.                                                                           \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mSensitivity:\u001b[0m The sensitivity analysis shows that a change of 0.0026 in the coefficient of \u001b[1;36;40mfeature_0\u001b[0m results in a\n",
       "\u001b[1;33m   \u001b[0mcorresponding change of -0.0026 in the expected change in the target variable when \u001b[1;36;40mfeature_0\u001b[0m increases from 1 to\n",
       "\u001b[1;33m   \u001b[0m2.  This is a direct, linear relationship as expected given the simple model structure implied by focusing on a \n",
       "\u001b[1;33m   \u001b[0msingle coefficient.                                                                                             \n",
       "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mExpected Change in Target:\u001b[0m The original model predicted a decrease of 0.4845 in the target variable when        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;36;40mfeature_0\u001b[0m changed from 1 to 2. The reduced model predicted a decrease of 0.4819. The difference between these   \n",
       "\u001b[1;33m   \u001b[0mpredictions (-0.0026) confirms the sensitivity calculation.                                                     \n",
       "\n",
       "\u001b[1mJustification:\u001b[0m                                                                                                     \n",
       "\n",
       "The output clearly shows the original and reduced coefficients for \u001b[1;36;40mfeature_0\u001b[0m. The \"Sensitivity\" value (0.0026) is  \n",
       "calculated as the difference between the original and reduced coefficients.  The \"Expected change in target\" values\n",
       "are calculated by multiplying the original/reduced coefficients by the change in \u001b[1;36;40mfeature_0\u001b[0m (2-1 = 1).  The \"Change \n",
       "in expected change\" is simply the difference between the expected changes calculated using the original and reduced\n",
       "models, and it matches the sensitivity value.                                                                      \n",
       "\n",
       "\u001b[1mIn conclusion,\u001b[0m the code successfully quantified the impact of a small change in the coefficient of \u001b[1;36;40mfeature_0\u001b[0m on the\n",
       "model's predictions. The sensitivity analysis demonstrates a linear relationship, where a decrease of 0.0026 in the\n",
       "coefficient leads to a decrease of 0.0026 in the predicted change in the target variable.  The absence of errors   \n",
       "indicates the code executed without issues.                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(Markdown(result['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86b4944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-19 00:03:19.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1müìÅ OutputManager initialized: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m276\u001b[0m - \u001b[1m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mEXECUTING: test\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1m======================================================================\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1müîß Executing code in: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/test/execution\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.493\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_code\u001b[0m:\u001b[36m162\u001b[0m - \u001b[31m\u001b[1m‚ùå Execution failed: Exit code: 1\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1müì¶ Saving outputs...\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_code\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1müíæ Saved code: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/test/20251119_000319_code_with_data.py\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_console_output\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1müìÑ Saved console output: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/test/console_output_20251119_000319.txt\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.output_manager\u001b[0m:\u001b[36msave_json\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1müìä Saved JSON: /Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/test/execution_info.json\u001b[0m\n",
      "\u001b[32m2025-11-19 00:03:19.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvariable_importance.utils.code_executer\u001b[0m:\u001b[36mexecute_with_output_manager\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m‚úÖ All outputs saved for test\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = await executor.execute_with_output_manager(\n",
    "        code=\"import pand\",\n",
    "        stage_name=\"test\",\n",
    "        output_manager=OutputManager(workflow_id=\"test_workflow_001\"),\n",
    "        code_filename=\"code_with_data.py\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eac92b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Traceback (most recent call last):\\n  File \\x1b[35m\"/Users/redam94/Coding/Ideas/variable_importance/exploration/results/test_workflow_001/test/execution/_agent_code.py\"\\x1b[0m, line \\x1b[35m11\\x1b[0m, in \\x1b[35m<module>\\x1b[0m\\n    import pand\\n\\x1b[1;35mModuleNotFoundError\\x1b[0m: \\x1b[35mNo module named \\'pand\\'\\x1b[0m\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f84ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variable-importance (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
